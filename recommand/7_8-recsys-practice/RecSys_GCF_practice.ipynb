{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFvr5ohQzfdZ"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "k0XsTBQRu2LQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: torch-geometric in c:\\users\\swsuser-k06\\appdata\\roaming\\python\\python312\\site-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in c:\\programdata\\miniconda3\\envs\\env_aias_test\\lib\\site-packages (from torch-geometric) (3.11.11)\n",
            "Requirement already satisfied: fsspec in c:\\programdata\\miniconda3\\envs\\env_aias_test\\lib\\site-packages (from torch-geometric) (2024.9.0)\n",
            "Requirement already satisfied: jinja2 in c:\\programdata\\miniconda3\\envs\\env_aias_test\\lib\\site-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in c:\\programdata\\miniconda3\\envs\\env_aias_test\\lib\\site-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in c:\\programdata\\miniconda3\\envs\\env_aias_test\\lib\\site-packages (from torch-geometric) (5.9.0)\n",
            "Requirement already satisfied: pyparsing in c:\\programdata\\miniconda3\\envs\\env_aias_test\\lib\\site-packages (from torch-geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in c:\\programdata\\miniconda3\\envs\\env_aias_test\\lib\\site-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in c:\\programdata\\miniconda3\\envs\\env_aias_test\\lib\\site-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\programdata\\miniconda3\\envs\\env_aias_test\\lib\\site-packages (from aiohttp->torch-geometric) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\miniconda3\\envs\\env_aias_test\\lib\\site-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\miniconda3\\envs\\env_aias_test\\lib\\site-packages (from aiohttp->torch-geometric) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\miniconda3\\envs\\env_aias_test\\lib\\site-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\miniconda3\\envs\\env_aias_test\\lib\\site-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\programdata\\miniconda3\\envs\\env_aias_test\\lib\\site-packages (from aiohttp->torch-geometric) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\programdata\\miniconda3\\envs\\env_aias_test\\lib\\site-packages (from aiohttp->torch-geometric) (1.18.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\miniconda3\\envs\\env_aias_test\\lib\\site-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\miniconda3\\envs\\env_aias_test\\lib\\site-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\miniconda3\\envs\\env_aias_test\\lib\\site-packages (from requests->torch-geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\miniconda3\\envs\\env_aias_test\\lib\\site-packages (from requests->torch-geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\miniconda3\\envs\\env_aias_test\\lib\\site-packages (from requests->torch-geometric) (2025.7.14)\n",
            "Requirement already satisfied: colorama in c:\\programdata\\miniconda3\\envs\\env_aias_test\\lib\\site-packages (from tqdm->torch-geometric) (0.4.6)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "\n",
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "duqURNMXu7y0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "from tqdm.notebook import tqdm\n",
        "from torch_geometric.data import download_url, extract_zip\n",
        "import math\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vY2LPcgBxICG"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXAK7dLMzbCV"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "01gvHmNrvP5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100836\n",
            "610\n",
            "9724\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using existing file ml-latest-small.zip\n",
            "Extracting .\\ml-latest-small.zip\n"
          ]
        }
      ],
      "source": [
        "url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
        "extract_zip(download_url(url, '.'), '.')\n",
        "\n",
        "ratings_path = './ml-latest-small/ratings.csv'\n",
        "rating_df = pd.read_csv(ratings_path)\n",
        "print(len(rating_df))\n",
        "print(rating_df['userId'].nunique())\n",
        "print(rating_df['movieId'].nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VT5MiJmnu71k"
      },
      "outputs": [],
      "source": [
        "# Transform UserID and MovieID into sequential indices\n",
        "user_encoder = {user: idx for idx, user in enumerate(rating_df['userId'].unique())}\n",
        "movie_encoder = {movie: idx for idx, movie in enumerate(rating_df['movieId'].unique())}\n",
        "\n",
        "rating_df['userId'] = rating_df['userId'].map(user_encoder)\n",
        "rating_df['movieId'] = rating_df['movieId'].map(movie_encoder)\n",
        "\n",
        "num_users = len(user_encoder)\n",
        "num_movies = len(movie_encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wIAZ0mJmu74m"
      },
      "outputs": [],
      "source": [
        "# Set seed for better replication\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(2025)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhBspxJszm5a"
      },
      "source": [
        "# Create Graph from Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "M50qdtthu77X"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[   0,    0,    0,  ...,  609,  609,  609],\n",
            "        [ 610,  611,  612,  ..., 3731, 2002, 3483]])\n"
          ]
        }
      ],
      "source": [
        "# Convert Explicit interaction as Implicit interaction\n",
        "# Create Edge for Graph\n",
        "# Generate edge between user and movie when user rates movie higher than (or equal to) 1\n",
        "\n",
        "#### 중요!: Adjacency matrix 대신 edge_index를 넣어서도 GNN 연산이 가능하다 ####\n",
        "def create_edge_index(df, rating_threshold=1.0):\n",
        "    src, dst = [], []\n",
        "    for _, row in df.iterrows():\n",
        "        if row['rating'] >= rating_threshold:\n",
        "            src.append(row['userId'])\n",
        "            # item indices after user indices\n",
        "            dst.append(row['movieId'] + num_users)\n",
        "    return torch.tensor([src, dst], dtype=torch.long)\n",
        "\n",
        "edge_index = create_edge_index(rating_df)\n",
        "print(edge_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "svaSzzkuu7_J"
      },
      "outputs": [],
      "source": [
        "# Split indices into train/val/test set (label for train/val/test set)\n",
        "train_indices, test_indices = train_test_split(range(edge_index.size(1)), test_size=0.2)\n",
        "val_indices, test_indices = train_test_split(test_indices, test_size=0.5)\n",
        "\n",
        "train_edge_index = edge_index[:, train_indices]\n",
        "val_edge_index = edge_index[:, val_indices]\n",
        "test_edge_index = edge_index[:, test_indices]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rE8kUvxbw1iP"
      },
      "source": [
        "# Model: NGCF\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp1SymhoBfN8"
      },
      "source": [
        "### Model Structure of NGCF\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <td style=\"text-align: center;\">\n",
        "      <img src=\"https://drive.google.com/uc?id=1J0FBPjW8IhYF87hIkuLEKH6gKIlZaRI3\" height=\"200\" width=\"300\">\n",
        "      <br>\n",
        "      <span>NGCF Model</span>\n",
        "    </td>\n",
        "  </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "RBFeilxuwCuj"
      },
      "outputs": [],
      "source": [
        "### TODO : NGCF Layer 완성 ###\n",
        "\n",
        "class NGCFLayer(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.W1 = nn.Linear(input_dim, output_dim)\n",
        "        self.W2 = nn.Linear(input_dim, output_dim)\n",
        "        # self.dropout = nn.Dropout(dropout)\n",
        "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self, edge_index, node_features, user_num, item_num):\n",
        "        '''\n",
        "        edge_index : 엣지 정보 (src, dst)의 집합.\n",
        "        node_features: node별 이전 layer에서 생성된 벡터 정보가 담긴 matrix (H^(l-1)) (|V| * d)\n",
        "        '''\n",
        "\n",
        "        src, dst = edge_index # src : user, dst : movie\n",
        "\n",
        "        # calculate node degree\n",
        "        deg = torch.zeros(node_features.size(0), device=node_features.device)\n",
        "        # calculate user degree\n",
        "        deg.index_add_(0, src, torch.ones_like(src, dtype=torch.float))\n",
        "        # calculate movie degree\n",
        "        deg.index_add_(0, dst, torch.ones_like(dst, dtype=torch.float))\n",
        "\n",
        "        # calculate 1/(root(deg(u)) * root(deg(i))) for all edge\n",
        "        norm = 1.0 / torch.sqrt(deg[src] * deg[dst])\n",
        "\n",
        "        src_feat = node_features[src] # H_u\n",
        "        dst_feat = node_features[dst] # H_i\n",
        "\n",
        "        # edge_messages for user(src) = m_(u<-i)) 결과 저장.\n",
        "        # Hint: step1. self.W1(h_i) + self.W2(h_u * h_i) 계산\n",
        "        # Hint: step2. 최종 m_(u<-i)를 위해선 앞선 norm을 앞서 계산한 message에 곱하기\n",
        "        edge_messages_for_src = self.W1(dst_feat) + self.W2(src_feat * dst_feat)\n",
        "        edge_messages_for_src *= norm.unsqueeze(1)\n",
        "\n",
        "        # edge_messages for movie(dst) = m_(i<-u)) 결과 저장.\n",
        "        # Hint: step1. self.W1(h_u) + self.W2(h_i * h_u) 계산\n",
        "        # Hint: step2. 최종 m_(i<-u)를 위해선 앞선 norm을 앞서 계산한 message에 곱하기\n",
        "        edge_messages_for_dst = self.W1(src_feat) + self.W2(dst_feat * src_feat)\n",
        "        edge_messages_for_dst *= norm.unsqueeze(1)\n",
        "\n",
        "        # aggregated_features = Combine()의 결과 저장.\n",
        "        aggregated_messages = torch.zeros_like(node_features)\n",
        "\n",
        "        # m_(u<-u) = self.W1(h_u) 계산해 더해주기\n",
        "        aggregated_messages.index_add(0, src, edge_messages_for_src)\n",
        "        aggregated_messages[:user_num] += self.W1(node_features[:user_num])\n",
        "\n",
        "        # m_(i<-i) = self.W1(h_i) 계산해 더해주기\n",
        "        aggregated_messages.index_add(0, dst, edge_messages_for_dst)\n",
        "        aggregated_messages[user_num:] += self.W1(node_features[user_num:])\n",
        "\n",
        "\n",
        "        aggregated_features = self.leaky_relu(aggregated_messages)\n",
        "\n",
        "        # engineering approach\n",
        "        # aggregated_features = self.dropout(aggregated_features)\n",
        "        return aggregated_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "zEmQZpltwCxv"
      },
      "outputs": [],
      "source": [
        "### TODO: NGCF 모델 완성.\n",
        "\n",
        "class NGCF(nn.Module):\n",
        "    def __init__(self, num_users, num_items, embedding_dim, layer_dims, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.num_users = num_users\n",
        "        self.num_items = num_items\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        ### self.node_embeddings = H_(0) = learnable embedding matrix ###\n",
        "        self.node_embeddings = nn.Embedding(self.num_users+self.num_items,self.embedding_dim)\n",
        "        nn.init.xavier_uniform_(self.node_embeddings.weight)\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            NGCFLayer(input_dim=(embedding_dim if i == 0 else layer_dims[i - 1]),\n",
        "                      output_dim=layer_dims[i], dropout=dropout)\n",
        "            for i in range(len(layer_dims))\n",
        "        ])\n",
        "\n",
        "    def forward(self, edge_index):\n",
        "        node_features = self.node_embeddings.weight\n",
        "        layer_outputs = [node_features]\n",
        "        for layer in self.layers:\n",
        "            node_features = layer(edge_index, node_features, self.num_users, self.num_items)\n",
        "            layer_outputs.append(node_features)\n",
        "\n",
        "        # Hint: NGCF의 final feature(representation)은 layer 별 feature에 대한 concatenated vector\n",
        "        # Hint: 최종 final feature matrix에는 [feuture_vector for users + feature_vector for items]가 들어있음.\n",
        "\n",
        "        final_features = torch.cat(layer_outputs, dim=1)\n",
        "        user_features = final_features[:self.num_users]\n",
        "        item_features = final_features[self.num_users:]\n",
        "        return user_features, item_features\n",
        "\n",
        "    def bpr_loss(self, user_emb, pos_item_emb, neg_item_emb, reg_weight=1e-4):\n",
        "        pos_scores = torch.sum(user_emb * pos_item_emb, dim=1)\n",
        "        neg_scores = torch.sum(user_emb * neg_item_emb, dim=1)\n",
        "        loss = -torch.mean(F.logsigmoid(pos_scores - neg_scores))\n",
        "        reg_loss = reg_weight * (user_emb.norm(2).pow(2) + pos_item_emb.norm(2).pow(2) \\\n",
        "                                 + neg_item_emb.norm(2).pow(2)) / user_emb.size(0)\n",
        "        return loss + reg_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOSD6d-mxalk"
      },
      "source": [
        "# Evaluation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Cgp9aTlDxLZn"
      },
      "outputs": [],
      "source": [
        "def evaluate(user_features, item_features, test_edge_index, k):\n",
        "    user_pos_items = defaultdict(list)\n",
        "    E_test = test_edge_index.size(1)\n",
        "    for i in range(E_test):\n",
        "        u = test_edge_index[0, i].item()\n",
        "        it = test_edge_index[1, i].item() - num_users\n",
        "        user_pos_items[u].append(it)\n",
        "\n",
        "    recalls, precisions, ndcgs = [], [], []\n",
        "    for user, pos_items in user_pos_items.items():\n",
        "        user_emb = user_features[user]\n",
        "        scores = torch.matmul(item_features, user_emb)\n",
        "        topk_scores, topk_indices = torch.topk(scores, k=k)\n",
        "        topk_indices = topk_indices.cpu().numpy().tolist()\n",
        "\n",
        "        hits = 0\n",
        "        dcg = 0.0\n",
        "        idcg = 0.0\n",
        "        n_pos = len(pos_items)\n",
        "\n",
        "        for rank, item_idx in enumerate(topk_indices):\n",
        "            if item_idx in pos_items:\n",
        "                hits += 1\n",
        "                dcg += 1.0 / math.log2(rank + 2)\n",
        "        for rank in range(min(n_pos, k)):\n",
        "            idcg += 1.0 / math.log2(rank + 2)\n",
        "\n",
        "        recall_u = hits / n_pos\n",
        "        precision_u = hits / k\n",
        "        ndcg_u = dcg / idcg if idcg > 0 else 0.0\n",
        "\n",
        "        recalls.append(recall_u)\n",
        "        precisions.append(precision_u)\n",
        "        ndcgs.append(ndcg_u)\n",
        "\n",
        "    recall = np.mean(recalls)\n",
        "    precision = np.mean(precisions)\n",
        "    ndcg = np.mean(ndcgs)\n",
        "    return recall, precision, ndcg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTdoFBfbxVGB"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "w7S-URkiwC3W"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, train_edge_index, val_edge_index, num_epochs, batch_size, device, k):\n",
        "    model.to(device)\n",
        "    train_edge_index = train_edge_index.to(device)\n",
        "    val_edge_index = val_edge_index.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        num_batches = len(train_edge_index[0]) // batch_size\n",
        "\n",
        "        for _ in range(num_batches):\n",
        "            indices = torch.randint(0, train_edge_index.size(1), (batch_size,), device=device)\n",
        "            user_indices = train_edge_index[0, indices]\n",
        "            pos_item_indices = train_edge_index[1, indices] - num_users\n",
        "            neg_item_indices = torch.randint(0, num_movies, (batch_size,), device=device)\n",
        "\n",
        "            user_features, item_features = model(train_edge_index)\n",
        "            u_emb = user_features[user_indices]\n",
        "            pos_emb = item_features[pos_item_indices]\n",
        "            neg_emb = item_features[neg_item_indices]\n",
        "\n",
        "            loss = model.bpr_loss(u_emb, pos_emb, neg_emb)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {total_loss / num_batches:.4f}\")\n",
        "\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                user_features, item_features = model(train_edge_index)\n",
        "                recall, precision, ndcg = evaluate(user_features.cpu(), item_features.cpu(), val_edge_index, k)\n",
        "                print(f\"[Validation] Epoch {epoch + 1}: Recall@{k}: {recall:.4f}, Precision@{k}: {precision:.4f}, NDCG@{k}: {ndcg:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKjpKw2FxSL2"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "NFojKq32xH-h"
      },
      "outputs": [],
      "source": [
        "def test(model, train_edge_index, test_edge_index, k, device):\n",
        "    model.eval()\n",
        "    train_edge_index = train_edge_index.to(device)\n",
        "    test_edge_index = test_edge_index.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        user_features, item_features = model(train_edge_index)\n",
        "\n",
        "    user_features = user_features.cpu()\n",
        "    item_features = item_features.cpu()\n",
        "\n",
        "    recall, precision, ndcg = evaluate(user_features, item_features, test_edge_index, k)\n",
        "    recall = round(recall, 4)\n",
        "    precision = round(precision, 4)\n",
        "    ndcg = round(ndcg, 4)\n",
        "\n",
        "    print(f\"Recall@{k}: {recall:.4f}, Precision@{k}: {precision:.4f}, NDCG@{k}: {ndcg:.4f}\")\n",
        "    return recall, precision, ndcg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7z_seKsxo-a"
      },
      "source": [
        "# Check Model Performace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "vBj6USK4xIFe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Train NGCF =====\n",
            "Epoch 1/30, Training Loss: 0.4962\n",
            "Epoch 2/30, Training Loss: 0.3373\n",
            "Epoch 3/30, Training Loss: 0.3261\n",
            "Epoch 4/30, Training Loss: 0.3229\n",
            "Epoch 5/30, Training Loss: 0.3221\n",
            "[Validation] Epoch 5: Recall@10: 0.0403, Precision@10: 0.0355, NDCG@10: 0.0442\n",
            "Epoch 6/30, Training Loss: 0.3147\n",
            "Epoch 7/30, Training Loss: 0.3148\n",
            "Epoch 8/30, Training Loss: 0.3098\n",
            "Epoch 9/30, Training Loss: 0.3087\n",
            "Epoch 10/30, Training Loss: 0.3084\n",
            "[Validation] Epoch 10: Recall@10: 0.0317, Precision@10: 0.0348, NDCG@10: 0.0422\n",
            "Epoch 11/30, Training Loss: 0.3090\n",
            "Epoch 12/30, Training Loss: 0.3006\n",
            "Epoch 13/30, Training Loss: 0.2965\n",
            "Epoch 14/30, Training Loss: 0.2890\n",
            "Epoch 15/30, Training Loss: 0.2808\n",
            "[Validation] Epoch 15: Recall@10: 0.0462, Precision@10: 0.0363, NDCG@10: 0.0508\n",
            "Epoch 16/30, Training Loss: 0.2708\n",
            "Epoch 17/30, Training Loss: 0.2589\n",
            "Epoch 18/30, Training Loss: 0.2575\n",
            "Epoch 19/30, Training Loss: 0.2490\n",
            "Epoch 20/30, Training Loss: 0.2407\n",
            "[Validation] Epoch 20: Recall@10: 0.0581, Precision@10: 0.0412, NDCG@10: 0.0583\n",
            "Epoch 21/30, Training Loss: 0.2351\n",
            "Epoch 22/30, Training Loss: 0.2319\n",
            "Epoch 23/30, Training Loss: 0.2251\n",
            "Epoch 24/30, Training Loss: 0.2186\n",
            "Epoch 25/30, Training Loss: 0.2173\n",
            "[Validation] Epoch 25: Recall@10: 0.0551, Precision@10: 0.0388, NDCG@10: 0.0549\n",
            "Epoch 26/30, Training Loss: 0.2165\n",
            "Epoch 27/30, Training Loss: 0.2132\n",
            "Epoch 28/30, Training Loss: 0.2053\n",
            "Epoch 29/30, Training Loss: 0.2028\n",
            "Epoch 30/30, Training Loss: 0.1998\n",
            "[Validation] Epoch 30: Recall@10: 0.0501, Precision@10: 0.0377, NDCG@10: 0.0529\n",
            "===== Test NGCF =====\n",
            "Recall@10: 0.0517, Precision@10: 0.0411, NDCG@10: 0.0536\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.0517, 0.0411, 0.0536)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ngcf_model = NGCF(num_users, num_movies, embedding_dim=64, layer_dims=[64, 64], dropout=0.1)\n",
        "optimizer_ngcf = torch.optim.Adam(ngcf_model.parameters(), lr=1e-3)\n",
        "\n",
        "print(\"===== Train NGCF =====\")\n",
        "train(\n",
        "    model=ngcf_model,\n",
        "    optimizer=optimizer_ngcf,\n",
        "    train_edge_index=train_edge_index,\n",
        "    val_edge_index=val_edge_index,\n",
        "    num_epochs=30,\n",
        "    batch_size=1024,\n",
        "    device=device,\n",
        "    k=10\n",
        ")\n",
        "\n",
        "print(\"===== Test NGCF =====\")\n",
        "test(\n",
        "    model=ngcf_model,\n",
        "    train_edge_index=train_edge_index,\n",
        "    test_edge_index=test_edge_index,\n",
        "    k=10,\n",
        "    device=device\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env_aias_test",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
