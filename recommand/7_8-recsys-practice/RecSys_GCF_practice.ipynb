{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "QFvr5ohQzfdZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0XsTBQRu2LQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "\n",
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "from tqdm.notebook import tqdm\n",
        "from torch_geometric.data import download_url, extract_zip\n",
        "import math\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "duqURNMXu7y0"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "vY2LPcgBxICG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "BXAK7dLMzbCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
        "extract_zip(download_url(url, '.'), '.')\n",
        "\n",
        "ratings_path = './ml-latest-small/ratings.csv'\n",
        "rating_df = pd.read_csv(ratings_path)\n",
        "print(len(rating_df))\n",
        "print(rating_df['userId'].nunique())\n",
        "print(rating_df['movieId'].nunique())"
      ],
      "metadata": {
        "id": "01gvHmNrvP5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform UserID and MovieID into sequential indices\n",
        "user_encoder = {user: idx for idx, user in enumerate(rating_df['userId'].unique())}\n",
        "movie_encoder = {movie: idx for idx, movie in enumerate(rating_df['movieId'].unique())}\n",
        "\n",
        "rating_df['userId'] = rating_df['userId'].map(user_encoder)\n",
        "rating_df['movieId'] = rating_df['movieId'].map(movie_encoder)\n",
        "\n",
        "num_users = len(user_encoder)\n",
        "num_movies = len(movie_encoder)"
      ],
      "metadata": {
        "id": "VT5MiJmnu71k"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seed for better replication\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(2025)"
      ],
      "metadata": {
        "id": "wIAZ0mJmu74m"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Graph from Data"
      ],
      "metadata": {
        "id": "JhBspxJszm5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Explicit interaction as Implicit interaction\n",
        "# Create Edge for Graph\n",
        "# Generate edge between user and movie when user rates movie higher than (or equal to) 1\n",
        "\n",
        "#### 중요!: Adjacency matrix 대신 edge_index를 넣어서도 GNN 연산이 가능하다 ####\n",
        "def create_edge_index(df, rating_threshold=1.0):\n",
        "    src, dst = [], []\n",
        "    for _, row in df.iterrows():\n",
        "        if row['rating'] >= rating_threshold:\n",
        "            src.append(row['userId'])\n",
        "            # item indices after user indices\n",
        "            dst.append(row['movieId'] + num_users)\n",
        "    return torch.tensor([src, dst], dtype=torch.long)\n",
        "\n",
        "edge_index = create_edge_index(rating_df)\n",
        "print(edge_index)"
      ],
      "metadata": {
        "id": "M50qdtthu77X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split indices into train/val/test set (label for train/val/test set)\n",
        "train_indices, test_indices = train_test_split(range(edge_index.size(1)), test_size=0.2)\n",
        "val_indices, test_indices = train_test_split(test_indices, test_size=0.5)\n",
        "\n",
        "train_edge_index = edge_index[:, train_indices]\n",
        "val_edge_index = edge_index[:, val_indices]\n",
        "test_edge_index = edge_index[:, test_indices]"
      ],
      "metadata": {
        "id": "svaSzzkuu7_J"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model: NGCF\n"
      ],
      "metadata": {
        "id": "rE8kUvxbw1iP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Structure of NGCF\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <td style=\"text-align: center;\">\n",
        "      <img src=\"https://drive.google.com/uc?id=1J0FBPjW8IhYF87hIkuLEKH6gKIlZaRI3\" height=\"200\" width=\"300\">\n",
        "      <br>\n",
        "      <span>NGCF Model</span>\n",
        "    </td>\n",
        "  </tr>\n",
        "</table>"
      ],
      "metadata": {
        "id": "tp1SymhoBfN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### TODO : NGCF Layer 완성 ###\n",
        "\n",
        "class NGCFLayer(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.W1 = nn.Linear(input_dim, output_dim)\n",
        "        self.W2 = nn.Linear(input_dim, output_dim)\n",
        "        # self.dropout = nn.Dropout(dropout)\n",
        "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self, edge_index, node_features, user_num, item_num):\n",
        "        '''\n",
        "        edge_index : 엣지 정보 (src, dst)의 집합.\n",
        "        node_features: node별 이전 layer에서 생성된 벡터 정보가 담긴 matrix (H^(l-1)) (|V| * d)\n",
        "        '''\n",
        "\n",
        "        src, dst = edge_index # src : user, dst : movie\n",
        "\n",
        "        # calculate node degree\n",
        "        deg = torch.zeros(node_features.size(0), device=node_features.device)\n",
        "        # calculate user degree\n",
        "        deg.index_add_(0, src, torch.ones_like(src, dtype=torch.float))\n",
        "        # calculate movie degree\n",
        "        deg.index_add_(0, dst, torch.ones_like(dst, dtype=torch.float))\n",
        "\n",
        "        # calculate 1/(root(deg(u)) * root(deg(i))) for all edge\n",
        "        norm = ## fill this part ##\n",
        "\n",
        "        src_feat = node_features[src] # H_u\n",
        "        dst_feat = node_features[dst] # H_i\n",
        "\n",
        "        # edge_messages for user(src) = m_(u<-i)) 결과 저장.\n",
        "        # Hint: step1. self.W1(h_i) + self.W2(h_u * h_i) 계산\n",
        "        # Hint: step2. 최종 m_(u<-i)를 위해선 앞선 norm을 앞서 계산한 message에 곱하기\n",
        "        edge_messages_for_src = self.W1(dst_feat) + self.W2(src_feat * dst_feat)\n",
        "        edge_messages_for_src *= norm.unsqueeze(1)\n",
        "\n",
        "        # edge_messages for movie(dst) = m_(i<-u)) 결과 저장.\n",
        "        # Hint: step1. self.W1(h_u) + self.W2(h_i * h_u) 계산\n",
        "        # Hint: step2. 최종 m_(i<-u)를 위해선 앞선 norm을 앞서 계산한 message에 곱하기\n",
        "        edge_messages_for_dst = ## fill this part ##\n",
        "        edge_messages_for_dst *= ## fill this part ##\n",
        "\n",
        "        # aggregated_features = Combine()의 결과 저장.\n",
        "        aggregated_messages = torch.zeros_like(node_features)\n",
        "\n",
        "        # m_(u<-u) = self.W1(h_u) 계산해 더해주기\n",
        "        aggregated_messages.index_add(0, src, edge_messages_for_src)\n",
        "        aggregated_messages[:user_num] += self.W1(node_features[:user_num])\n",
        "\n",
        "        # m_(i<-i) = self.W1(h_i) 계산해 더해주기\n",
        "        ## Fill this part ##\n",
        "\n",
        "\n",
        "        aggregated_features = self.leaky_relu(aggregated_messages)\n",
        "\n",
        "        # engineering approach\n",
        "        # aggregated_features = self.dropout(aggregated_features)\n",
        "        return aggregated_features"
      ],
      "metadata": {
        "id": "RBFeilxuwCuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### TODO: NGCF 모델 완성.\n",
        "\n",
        "class NGCF(nn.Module):\n",
        "    def __init__(self, num_users, num_items, embedding_dim, layer_dims, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.num_users = num_users\n",
        "        self.num_items = num_items\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        ### self.node_embeddings = H_(0) = learnable embedding matrix ###\n",
        "        self.node_embeddings = nn.Embedding(self.num_users+self.num_items,self.embedding_dim)\n",
        "        nn.init.xavier_uniform_(self.node_embeddings.weight)\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            NGCFLayer(input_dim=(embedding_dim if i == 0 else layer_dims[i - 1]),\n",
        "                      output_dim=layer_dims[i], dropout=dropout)\n",
        "            for i in range(len(layer_dims))\n",
        "        ])\n",
        "\n",
        "    def forward(self, edge_index):\n",
        "        node_features = self.node_embeddings.weight\n",
        "        layer_outputs = [node_features]\n",
        "        for layer in self.layers:\n",
        "            node_features = ## fill this part ##\n",
        "            layer_outputs.append(node_features)\n",
        "\n",
        "        # Hint: NGCF의 final feature(representation)은 layer 별 feature에 대한 concatenated vector\n",
        "        # Hint: 최종 final feature matrix에는 [feuture_vector for users + feature_vector for items]가 들어있음.\n",
        "\n",
        "        final_features = ## fill this part ##\n",
        "        user_features = ## fill this part ##\n",
        "        item_features = ## fill this part ##\n",
        "        return user_features, item_features\n",
        "\n",
        "    def bpr_loss(self, user_emb, pos_item_emb, neg_item_emb, reg_weight=1e-4):\n",
        "        pos_scores = torch.sum(user_emb * pos_item_emb, dim=1)\n",
        "        neg_scores = torch.sum(user_emb * neg_item_emb, dim=1)\n",
        "        loss = -torch.mean(F.logsigmoid(pos_scores - neg_scores))\n",
        "        reg_loss = reg_weight * (user_emb.norm(2).pow(2) + pos_item_emb.norm(2).pow(2) \\\n",
        "                                 + neg_item_emb.norm(2).pow(2)) / user_emb.size(0)\n",
        "        return loss + reg_loss"
      ],
      "metadata": {
        "id": "zEmQZpltwCxv"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation Function"
      ],
      "metadata": {
        "id": "XOSD6d-mxalk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(user_features, item_features, test_edge_index, k):\n",
        "    user_pos_items = defaultdict(list)\n",
        "    E_test = test_edge_index.size(1)\n",
        "    for i in range(E_test):\n",
        "        u = test_edge_index[0, i].item()\n",
        "        it = test_edge_index[1, i].item() - num_users\n",
        "        user_pos_items[u].append(it)\n",
        "\n",
        "    recalls, precisions, ndcgs = [], [], []\n",
        "    for user, pos_items in user_pos_items.items():\n",
        "        user_emb = user_features[user]\n",
        "        scores = torch.matmul(item_features, user_emb)\n",
        "        topk_scores, topk_indices = torch.topk(scores, k=k)\n",
        "        topk_indices = topk_indices.cpu().numpy().tolist()\n",
        "\n",
        "        hits = 0\n",
        "        dcg = 0.0\n",
        "        idcg = 0.0\n",
        "        n_pos = len(pos_items)\n",
        "\n",
        "        for rank, item_idx in enumerate(topk_indices):\n",
        "            if item_idx in pos_items:\n",
        "                hits += 1\n",
        "                dcg += 1.0 / math.log2(rank + 2)\n",
        "        for rank in range(min(n_pos, k)):\n",
        "            idcg += 1.0 / math.log2(rank + 2)\n",
        "\n",
        "        recall_u = hits / n_pos\n",
        "        precision_u = hits / k\n",
        "        ndcg_u = dcg / idcg if idcg > 0 else 0.0\n",
        "\n",
        "        recalls.append(recall_u)\n",
        "        precisions.append(precision_u)\n",
        "        ndcgs.append(ndcg_u)\n",
        "\n",
        "    recall = np.mean(recalls)\n",
        "    precision = np.mean(precisions)\n",
        "    ndcg = np.mean(ndcgs)\n",
        "    return recall, precision, ndcg"
      ],
      "metadata": {
        "id": "Cgp9aTlDxLZn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "gTdoFBfbxVGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, train_edge_index, val_edge_index, num_epochs, batch_size, device, k):\n",
        "    model.to(device)\n",
        "    train_edge_index = train_edge_index.to(device)\n",
        "    val_edge_index = val_edge_index.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        num_batches = len(train_edge_index[0]) // batch_size\n",
        "\n",
        "        for _ in range(num_batches):\n",
        "            indices = torch.randint(0, train_edge_index.size(1), (batch_size,), device=device)\n",
        "            user_indices = train_edge_index[0, indices]\n",
        "            pos_item_indices = train_edge_index[1, indices] - num_users\n",
        "            neg_item_indices = torch.randint(0, num_movies, (batch_size,), device=device)\n",
        "\n",
        "            user_features, item_features = model(train_edge_index)\n",
        "            u_emb = user_features[user_indices]\n",
        "            pos_emb = item_features[pos_item_indices]\n",
        "            neg_emb = item_features[neg_item_indices]\n",
        "\n",
        "            loss = model.bpr_loss(u_emb, pos_emb, neg_emb)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {total_loss / num_batches:.4f}\")\n",
        "\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                user_features, item_features = model(train_edge_index)\n",
        "                recall, precision, ndcg = evaluate(user_features.cpu(), item_features.cpu(), val_edge_index, k)\n",
        "                print(f\"[Validation] Epoch {epoch + 1}: Recall@{k}: {recall:.4f}, Precision@{k}: {precision:.4f}, NDCG@{k}: {ndcg:.4f}\")"
      ],
      "metadata": {
        "id": "w7S-URkiwC3W"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "cKjpKw2FxSL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, train_edge_index, test_edge_index, k, device):\n",
        "    model.eval()\n",
        "    train_edge_index = train_edge_index.to(device)\n",
        "    test_edge_index = test_edge_index.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        user_features, item_features = model(train_edge_index)\n",
        "\n",
        "    user_features = user_features.cpu()\n",
        "    item_features = item_features.cpu()\n",
        "\n",
        "    recall, precision, ndcg = evaluate(user_features, item_features, test_edge_index, k)\n",
        "    recall = round(recall, 4)\n",
        "    precision = round(precision, 4)\n",
        "    ndcg = round(ndcg, 4)\n",
        "\n",
        "    print(f\"Recall@{k}: {recall:.4f}, Precision@{k}: {precision:.4f}, NDCG@{k}: {ndcg:.4f}\")\n",
        "    return recall, precision, ndcg"
      ],
      "metadata": {
        "id": "NFojKq32xH-h"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check Model Performace"
      ],
      "metadata": {
        "id": "l7z_seKsxo-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ngcf_model = NGCF(num_users, num_movies, embedding_dim=64, layer_dims=[64, 64], dropout=0.1)\n",
        "optimizer_ngcf = torch.optim.Adam(ngcf_model.parameters(), lr=1e-3)\n",
        "\n",
        "print(\"===== Train NGCF =====\")\n",
        "train(\n",
        "    model=ngcf_model,\n",
        "    optimizer=optimizer_ngcf,\n",
        "    train_edge_index=train_edge_index,\n",
        "    val_edge_index=val_edge_index,\n",
        "    num_epochs=30,\n",
        "    batch_size=1024,\n",
        "    device=device,\n",
        "    k=10\n",
        ")\n",
        "\n",
        "print(\"===== Test NGCF =====\")\n",
        "test(\n",
        "    model=ngcf_model,\n",
        "    train_edge_index=train_edge_index,\n",
        "    test_edge_index=test_edge_index,\n",
        "    k=10,\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "id": "vBj6USK4xIFe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}