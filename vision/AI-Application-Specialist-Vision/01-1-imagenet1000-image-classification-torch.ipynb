{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f94a9560",
   "metadata": {},
   "source": [
    "# Image Classification using the pre-trained ImageNet-1k dataset\n",
    "\n",
    "### To use the pretrained models using ImageNet 1000 for image classification\n",
    "### Trained Dataset: ImageNet 1000\n",
    "\n",
    "### - AI Tool: pytorch, torchvision\n",
    "### - Use pretrained models \n",
    "### - models: ResNet50, VGG16, VGG19\n",
    "### - Reference \n",
    "  - [torchvision.models](https://docs.pytorch.org/vision/main/models.html):\n",
    "    [ResNet50](https://docs.pytorch.org/vision/main/models/generated/torchvision.models.resnet50.html),\n",
    "    [VGG19](https://docs.pytorch.org/vision/main/models/generated/torchvision.models.vgg19.html#torchvision.models.vgg19), \n",
    "    [VGG16](https://docs.pytorch.org/vision/main/models/generated/torchvision.models.vgg16.html#torchvision.models.vgg16)\n",
    "  - imagenet 1000 class list: \n",
    "     [keras-imagenet_class_index.json](https://github.com/raghakot/keras-vis/blob/master/resources/imagenet_class_index.json),\n",
    "     [Class ID-Class Name Table](https://deeplearning.cms.waikato.ac.nz/user-guide/class-maps/IMAGENET/),                                  [clsidx_to_lables.txt](https://gist.github.com/aaronpolhamus/964a4411c0906315deb9f4a3723aac57)\n",
    " \n",
    "  - imagenet-1k Dataset card: https://huggingface.co/datasets/imagenet-1k\n",
    "  - image-net.org: https://www.image-net.org/update-mar-11-2021.php\n",
    "  - [Using keras: image classifications](https://keras.io/api/applications/)\n",
    " \n",
    "## **실습** \n",
    "  - image classification을 알아보기\n",
    "  - input, output, preprocess, model, inference(predict) 이해하기\n",
    "  - web에 있는 image로 test해 보세요(검색, browsing사용).\n",
    "    * 단, 접속되는 site가 제한될 수 있으니, 접속이 안되면 다른 site를 시도해 보세요.\n",
    "  - model architecture 보기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c096586b-9ffd-4b45-8e08-9cc04c931711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms.functional as F\n",
    "from torchvision.io import decode_image\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ea6982-ad36-4f2e-8fd0-096243199afc",
   "metadata": {},
   "source": [
    "## Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42affb95-68a1-42ef-828c-b04eeb923fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test images 포함한 폴더\n",
    "img_path = './images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80afb3e5-59ad-4759-b91a-162303a9c334",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.platform == 'win32':\n",
    "    # path change to windows\n",
    "    img_path = '.\\\\images\\\\'\n",
    "    !dir {img_path} /B \n",
    "else:\n",
    "    !ls $img_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b4cfe2-3d39-4d51-b2ba-09e4bbe64e2e",
   "metadata": {},
   "source": [
    "### load an image from url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e933f0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image from url\n",
    "import urllib\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "def load_image_url(url):\n",
    "    return Image.open(requests.get(url, stream=True).raw) # PIL format\n",
    "    \n",
    "def load_image_url2(URL):\n",
    "    with urllib.request.urlopen(URL) as url:\n",
    "        img_file = BytesIO(url.read())\n",
    "        img = Image.open(img_file)\n",
    "\n",
    "    return img # PIL format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce09685-9d01-4114-8d1a-cdea88f47236",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56ea81f-d74a-4303-addc-25f96fec71bb",
   "metadata": {},
   "source": [
    "## Load a model for image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ac5d81-b575-444c-90fe-a23b400097c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = models.ResNet50_Weights.DEFAULT\n",
    "resnet50 = models.resnet50(weights=weights)\n",
    "#resnet50 = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a31a9e8-8c70-446b-a63b-848febc71934",
   "metadata": {},
   "source": [
    "### Loading an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd6a787-72e7-4017-af94-aa1db29e4d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. load from an image in the local directory\n",
    "img_file = img_path + 'elephant.jpg'\n",
    "img = decode_image(img_file) #,  # Loads an image into PIL format\n",
    "img = F.to_pil_image(img.detach())\n",
    "plt.imshow(img)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061f7afb-ec6c-4ffb-ba1a-9e9986b7f870",
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222e7996-a171-47db-8943-04e9abc2eae7",
   "metadata": {},
   "source": [
    "### image classification given an image\n",
    "- inference or predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81acfdac-cc88-4a4c-b1ce-fac6f3adb5ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resnet50.eval()\n",
    "\n",
    "preprocess = weights.transforms()\n",
    "\n",
    "x = preprocess(img).unsqueeze(0)\n",
    "preds = resnet50(x).squeeze(0).softmax(0)\n",
    "class_id = preds.argmax().item()\n",
    "score = preds[class_id].item()\n",
    "category_name = weights.meta['categories'][class_id]\n",
    "print(f'Predicted: {category_name}: {score:.1f}')\n",
    "\n",
    "topk_probs, topk_class_ids = torch.topk(preds, k=3)\n",
    "print(f'Predicted:', end='') \n",
    "for p, class_id in zip(topk_probs, topk_class_ids):\n",
    "    print(f' {weights.meta['categories'][class_id]}({p:.1f}),', end='')\n",
    "print('') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b248cd3-9fa7-49e4-8118-29329517f672",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.size, x.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e2ae7c-5491-4bd9-b074-3aee4b19c712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. url에서 직접 download하여 test\n",
    "img_url1 = 'https://d1bg8rd1h4dvdb.cloudfront.net/img/storypick/monamipet/2019/01/1811_pet_dog_pomeranian_m_01.jpg'\n",
    "img_url2 = 'https://github.com/pytorch/hub/raw/master/images/dog.jpg'\n",
    "img1 = load_image_url(img_url1)\n",
    "img2 = load_image_url(img_url2)\n",
    "plt.subplot(121)\n",
    "plt.imshow(img1)\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.imshow(img2)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d34fc8-acc0-4adb-b346-7fc5747630a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, weights, img):\n",
    "    # weights: are sused for preprocess(image), meta['cateogries'][class_id] (category name) \n",
    "    model.eval()\n",
    "\n",
    "    preprocess = weights.transforms() # preprocess_input\n",
    "\n",
    "    x = preprocess(img).unsqueeze(0)\n",
    "    preds = model(x).squeeze(0).softmax(0)\n",
    "    class_id = preds.argmax().item()\n",
    "    score = preds[class_id].item()\n",
    "    category_name = weights.meta['categories'][class_id]\n",
    "\n",
    "    topk_probs, topk_class_ids = torch.topk(preds, k=3)\n",
    "    print (topk_probs)\n",
    "    print(f'Predicted:', end='') \n",
    "    for p, class_id in zip(topk_probs, topk_class_ids):\n",
    "        print(f' {weights.meta['categories'][class_id]}({p:.3f}),', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341919c0-fa2f-4376-a919-5ba2c01447a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(resnet50, weights, img1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3655cd4e-fe3b-4949-8a49-1416bbda6f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(resnet50, weights, img2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8092b17-a371-4e39-83e2-d8f9ab1894e3",
   "metadata": {},
   "source": [
    "## Model 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfee986b-ac22-46fd-a463-141599caaafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdcc822-6d0c-40c3-89e0-1721b1f972bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(resnet50, [1, 3, 224, 224])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd49362d-765f-4bec-8aff-102348356a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9325b5e-5155-45c4-9785-0f191790f56f",
   "metadata": {},
   "source": [
    "## Use VGG16, VGG19\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f52bc78-5b94-4764-ac9e-45ed2165011c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_weights = models.VGG19_Weights.IMAGENET1K_V1\n",
    "vgg16_weights = models.VGG16_Weights.IMAGENET1K_V1\n",
    "vgg19_model = models.vgg19(weights=vgg19_weights)\n",
    "vgg16_model = models.vgg16(weights=vgg16_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8872ca1c-92f1-4505-b95e-830dacdc43db",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(vgg16_model, vgg16_weights, img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7402170-e03b-432b-b74e-65d4b91b5083",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(vgg19_model, vgg19_weights, img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3243e639-17a4-4829-a064-68501b39feaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(vgg19_model, vgg19_weights, img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923d306e-cc08-445b-b180-f8273fa9feda",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(vgg16_model, vgg19_weights, img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456e9e4f-33be-4870-b697-2076fab021b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vgg19_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e976b61-3906-4366-a2c2-11ca6773ec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(vgg19_model, input_size=[1, 3, 224, 224])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a8a5c2-8b5b-4afa-bd14-b0403f8c4382",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(models.VGG19_Weights.IMAGENET1K_V1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2250f7e",
   "metadata": {},
   "source": [
    "# [참고]\n",
    "## MobileNet v2, v3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e23182f-7459-4cee-87b9-a2d8ce301215",
   "metadata": {},
   "source": [
    "### Use VGG16, VGG19\n",
    "- You may use to extract features with VGG16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e72cf49-d5f4-46a4-abff-8a5e29959702",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
