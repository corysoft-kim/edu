{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48be7ce9",
   "metadata": {},
   "source": [
    "## DDPM Generate an image using Diffusers \n",
    "- 영상 생성하는 reverse process를 살펴보자.\n",
    "- forward process를 기억하며 이해해 보자.\n",
    "\n",
    "### 참조\n",
    "- Reference [diffusers_intro](https://github.com/huggingface/notebooks/blob/main/diffusers/diffusers_intro.ipynb), [training_example](https://github.com/huggingface/notebooks/blob/main/diffusers/training_example.ipynb)\n",
    "- Requirements: diffusers, pytorch \n",
    "\n",
    "### Installation\n",
    "- Install `!pip install diffusers==0.11.1`\n",
    "- Install `!pip install accelerate`  \n",
    "  if you see the following message    \n",
    "  ```\n",
    "  Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
    "    - Install `pip install diffusers[training]==0.11.1\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cee36a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image as DisplayImage\n",
    "\n",
    "# disable warning message\n",
    "import torchvision \n",
    "torchvision.disable_beta_transforms_warning()\n",
    "\n",
    "from diffusers import DDPMPipeline\n",
    "\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a4cef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_drive = '\\\\\\\\swschoolavdazfiles002.file.core.windows.net\\\\aias-vision'\n",
    "dataset_path = n_drive + '\\\\' + 'AI-Application-Specialist-Vision-Dataset' \n",
    "\n",
    "DisplayImage(filename=dataset_path  + \"\\\\\" + 'hf-assets/ddpm_paper.png', width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856b9b91-dc98-415d-8733-b0886e28a6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  # 'linux', 'win32'\n",
    "import os #'nt','posix'\n",
    "if sys.platform == 'linux': # mlp\n",
    "    # in order to download models from huggingface in the ML Platform, it is necessary to set the following proxy and ssl \n",
    "    import ssl\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "    # suwon\n",
    "    import os\n",
    "    os.environ['REQUESTS_CA_BUNDLE'] = '/etc/ssl/certs/ca-certificates.crt'\n",
    "    os.environ['HTTP_PROXY'] ='http://75.17.107.42:8080'\n",
    "    os.environ['HTTPS_PROXY'] ='http://75.17.107.42:8080'\n",
    "elif sys.platform == 'win32':\n",
    "    os.environ[\"PATH\"]+= os.pathsep+\"C:\\\\Program Files\\\\Graphviz\\\\bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5b2a73-0deb-4e58-ab56-8f3d448819ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cache_path = 'd:/HF_cache'\n",
    "os.environ['HF_HOME'] = cache_path\n",
    "os.environ['TRANSFORMERS_CACHE'] = cache_path # seems not to work\n",
    "os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = 'false' # hg download 시 warning disable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0cf4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "hf_model_dir = dataset_path + \"hf-models/\"\n",
    "download_from_local = False # True if downloading from this local system, False if downloading from remote huggingface sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e789f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"google/ddpm-cat-256\"\n",
    "# model_id = \"google/ddpm-celebahq-256\"\n",
    "# model_id = \"google/ddpm-church-256\"\n",
    "\n",
    "if download_from_local == True: # download from local folder \n",
    "    repo_id = hf_model_dir+model_id\n",
    "else: # directly to download from huggingface \n",
    "    repo_id = model_id\n",
    "    \n",
    "ddpm_pipe = DDPMPipeline.from_pretrained(repo_id, cache_dir=cache_path)\n",
    "ddpm_pipe.to(device)\n",
    "ddpm_pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd222455",
   "metadata": {},
   "source": [
    "## 1. pre-trained model로 image를 생성하는 방법\n",
    "- diffusion steps로 sample하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc825816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_inference_steps: the number of diffusion steps used when generating samples with a pre-trained model\n",
    "# ddpm num_inference_steps = 1000\n",
    "images = ddpm_pipe().images\n",
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f412936c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2050890",
   "metadata": {},
   "source": [
    "## 2. sampling step을 단계적으로 진행\n",
    "- huggingface DDPMPipeline은 UNet2DModel과 DDPMScheduler로 구성됨\n",
    "- 표준 정규 분포에서 noise image sample 생성 ($x_T$)\n",
    "- UNet2DModel().sample 은 현재 noisy sample($x_t$), t를 입력으로 noise residual($e_t$)을 \n",
    "  prediction함  \n",
    "  : $(x_t, t)$ &rarr; $e_t$\n",
    "- DDPMScheduler.step().prev_sample: noise residual을 사용하여 less noisy image를 sampling함  \n",
    "  : ($e_t, t, x_t$) &rarr; $x_{t-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49ae966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import UNet2DModel\n",
    "\n",
    "model_id = \"google/ddpm-church-256\"\n",
    "\n",
    "if download_from_local == True:\n",
    "    repo_id = hf_model_dir + model_id\n",
    "else: \n",
    "    repo_id = model_id\n",
    "    \n",
    "model = UNet2DModel.from_pretrained(repo_id, cache_dir=cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3189031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af69dfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e82fae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random image at time=T\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# 1) to sample a random noise image [C, H, W] from a Normal distribution N(0, I)\n",
    "noisy_sample = torch.randn(\n",
    "    1, model.config.in_channels, model.config.sample_size, model.config.sample_size\n",
    ")\n",
    "noisy_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13a7464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "import numpy as np\n",
    "\n",
    "def display_sample(sample, t):\n",
    "    image_processed = sample.cpu().permute(0, 2, 3, 1)\n",
    "    image_processed = (image_processed + 1.0) * 127 # 127.5\n",
    "    image_processed = torch.clamp(image_processed, min=0, max=255)\n",
    "    image_processed = image_processed.numpy().astype(np.uint8)\n",
    "\n",
    "    image_pil = PIL.Image.fromarray(image_processed[0])\n",
    "    display(f\"Image at step {t}\")\n",
    "    display(image_pil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96808ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_sample(noisy_sample,999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ce5db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) model을 사용하여 noisy_residual 을 prediction함\n",
    "# - input: sample(현재 noise sample), timestep (t)\n",
    "# - output: previous noisy residual\n",
    "with torch.no_grad():\n",
    "    noisy_residual = model(sample=noisy_sample, timestep=999).sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1aad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_residual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af66d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DDPMScheduler\n",
    "\n",
    "scheduler = DDPMScheduler.from_pretrained(repo_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee39a918",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172dfcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) model을 이용하여 timestep t에서 예측된 noisy_residual를 사용하여  \n",
    "# 좀더 noisy가 적은(less_noisy_sample image) t-1의 previsous image를 sampling \n",
    "# : DDPM reverse process - sampling 단계\n",
    "less_noisy_sample = scheduler.step(\n",
    "    model_output=noisy_residual, timestep=999, sample=noisy_sample\n",
    ").prev_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad783fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_residual.shape, less_noisy_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59630535",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_sample(less_noisy_sample,998)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60368e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from 'cpu' to 'cuda' gpu\n",
    "model.to(device)\n",
    "noisy_sample = noisy_sample.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a913693",
   "metadata": {},
   "source": [
    "### 4) model과 scheduler를 사용하여 연속적으로 timesteps reverse process 진행하면서 중간 결과를 살펴보자.\n",
    "- noise sample image에서 점차로 영상으로 진행해 가는 과정을 살펴보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2530fd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "sample = noisy_sample\n",
    "\n",
    "for i, t in enumerate(tqdm.tqdm(scheduler.timesteps)):\n",
    "    # 1. predict noise residual\n",
    "    with torch.no_grad():\n",
    "        residual = model(sample, t).sample\n",
    "\n",
    "    # 2. compute less noisy image and set x_t -> x_t-1\n",
    "    sample = scheduler.step(residual, t, sample).prev_sample\n",
    "\n",
    "    # 3. optionally look at image\n",
    "    if (i + 1) % 50 == 0:\n",
    "        display_sample(sample, i + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8add83",
   "metadata": {},
   "source": [
    "### DDIM Scheduler\n",
    "- scheduler를 DDIM 방식으로 변경하여 실습해 보자.\n",
    "- 차이가 무엇인가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0841cf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DDIMScheduler\n",
    "\n",
    "scheduler = DDIMScheduler.from_pretrained(repo_id, cache_dir=cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4177e532",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432cadfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler.set_timesteps(num_inference_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a02101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "sample = noisy_sample\n",
    "\n",
    "for i, t in enumerate(tqdm.tqdm(scheduler.timesteps)):\n",
    "    # 1. predict noise residual\n",
    "    with torch.no_grad():\n",
    "        residual = model(sample, t).sample\n",
    "\n",
    "    # 2. compute previous image and set x_t -> x_t-1\n",
    "    sample = scheduler.step(residual, t, sample).prev_sample\n",
    "\n",
    "    # 3. optionally look at image\n",
    "    if (i + 1) % 10 == 0:\n",
    "        display_sample(sample, i + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba03efbb",
   "metadata": {},
   "source": [
    "### cifar10-ddpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b237f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install diffusers\n",
    "from diffusers import DDPMPipeline, DDIMPipeline, PNDMPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49647d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and scheduler\n",
    "if download_from_local == True:\n",
    "    model_id = hf_model_dir + \"google/ddpm-cifar10-32\"\n",
    "else: \n",
    "    model_id = \"google/ddpm-cifar10-32\"\n",
    "    \n",
    "ddpm = DDPMPipeline.from_pretrained(model_id, cache_dir=cache_path)  # you can replace DDPMPipeline with DDIMPipeline or PNDMPipeline for faster inference\n",
    "ddpm = ddpm.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8c8f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run pipeline in inference (sample random noise and denoise)\n",
    "t0 = time.time()\n",
    "image = ddpm().images[0]\n",
    "print(time.time()-t0)\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793ac996",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddim = DDIMPipeline.from_pretrained(model_id, cache_dir=cache_path)  # you can replace DDPMPipeline with DDIMPipeline or PNDMPipeline for faster inference\n",
    "ddim = ddim.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc4eb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run pipeline in inference (sample random noise and denoise)\n",
    "t0 = time.time()\n",
    "image = ddim().images[0]\n",
    "print(time.time()-t0)\n",
    "\n",
    "# to save image\n",
    "# image.save(\"ddim_generated_image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9946c228",
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613175b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
