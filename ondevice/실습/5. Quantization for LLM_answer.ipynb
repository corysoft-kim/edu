{"cells":[{"cell_type":"markdown","id":"07b998ce","metadata":{"id":"07b998ce"},"source":["# Assignment 4. Quantization for LLM\n"]},{"cell_type":"markdown","id":"e9df27e7","metadata":{"id":"e9df27e7"},"source":["## Goals\n","\n","ë³¸ ì‹¤ìŠµì—ì„œëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(Large Language Model, LLM)ì— ëŒ€í•´ ì–‘ìí™”(Quantization)ì„ ìˆ˜í–‰í•˜ì—¬ ëª¨ë¸ì„ ì••ì¶•í•˜ëŠ” ë°©ë²•ì„ ì‹¤ìŠµí•©ë‹ˆë‹¤.\n","\n","LLMì€ íŒŒë¼ë¯¸í„°ì˜ ê°œìˆ˜ê°€ ë§¤ìš° ë§ê¸° ë•Œë¬¸ì— ì¼ë°˜ì ìœ¼ë¡œ FP16ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤. ê·¸ëŸ¼ì—ë„ íŒŒë¼ë¯¸í„°ì˜ í¬ê¸°ê°€ ë§ì´ í¬ë©°, LLaMA-2 7Bì™€ ê°™ì´ ì‘ì€ ëª¨ë¸ì— ëŒ€í•´ì„œë„ ëª¨ë°”ì¼ í™˜ê²½ì—ì„œ ìˆ˜í–‰í•˜ê³ ì í•˜ëŠ” ê²½ìš° FP16ì—ì„œë„ ìµœì†Œ 14GB ì´ìƒì˜ ë©”ëª¨ë¦¬ë¥¼ ìš”êµ¬í•˜ë©° ì´ëŠ” ì‹¤ì œë¡œ ëŒë¦¬ê¸°ì— ë¬´ë¦¬ê°€ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, ì–‘ìí™”ë¥¼ í†µí•´ ëª¨ë¸ì˜ weightë¥¼ ë” ë‚®ì€ precisionìœ¼ë¡œ ì••ì¶•í•˜ëŠ” ê²ƒì´ ê°€ëŠ¥í•©ë‹ˆë‹¤."]},{"cell_type":"markdown","id":"8aeb698d","metadata":{"id":"8aeb698d"},"source":["## Contents\n","1. Weight-only Quantization\n","  - Weightë§Œ quantizationì„ ì ìš©í•©ë‹ˆë‹¤.\n","  - ì¥ì : ë§¤ìš° ë‚®ì€ bit-widthë¡œ weightë¥¼ ì–‘ìí™”í•  ìˆ˜ ìˆìœ¼ë©°, ë‹¨ì¼ ë°°ì¹˜ ì¶”ë¡  í™˜ê²½ì—ì„œ ìœ ë¦¬í•©ë‹ˆë‹¤.\n","  - ë‹¨ì : Dequantization í›„ FP16 ì—°ì‚°ì„ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤.\n","  - ì˜ˆì‹œ: AWQ (W3A16, W4A16)\n","2. Weight and Activation Quantization\n","  - Weightì™€ activation ëª¨ë‘ quantizationì„ ì ìš©í•©ë‹ˆë‹¤.\n","  - ì¥ì : ë‚®ì€ precisionì˜ ì—°ì‚°ì„ í†µí•´ ê°€ì† ê°€ëŠ¥í•˜ë©°, ëŒ€ê·œëª¨ ë°°ì¹˜ ì¶”ë¡  í™˜ê²½ì—ì„œ ìœ ë¦¬í•©ë‹ˆë‹¤.\n","  - ë‹¨ì : weightì˜ bit-widthë¥¼ ë‚®ì¶”ê¸°ì— í•œê³„ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.\n","  - ì˜ˆì‹œ: SmoothQuant (W8A8)"]},{"cell_type":"markdown","id":"174d2d1e","metadata":{"id":"174d2d1e"},"source":["## Setup"]},{"cell_type":"markdown","id":"e70247c0","metadata":{"id":"e70247c0"},"source":["ì‹¤ìŠµì— í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":null,"id":"2797112a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2797112a","outputId":"9c8b0ccb-811f-461a-991e-447a9c0421f5","executionInfo":{"status":"ok","timestamp":1752459072241,"user_tz":-540,"elapsed":26693,"user":{"displayName":"ì¡°í˜„ë˜","userId":"14418074065025293504"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Installing packages...\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: transformers==4.31.0 in /usr/local/lib/python3.11/dist-packages (4.31.0)\n","Requirement already satisfied: accelerate==0.21.0 in /usr/local/lib/python3.11/dist-packages (0.21.0)\n","Requirement already satisfied: sentencepiece==0.1.99 in /usr/local/lib/python3.11/dist-packages (0.1.99)\n","Requirement already satisfied: tokenizers==0.13.3 in /usr/local/lib/python3.11/dist-packages (0.13.3)\n","Requirement already satisfied: datasets==2.15.0 in /usr/local/lib/python3.11/dist-packages (2.15.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n","Requirement already satisfied: zstandard in /usr/local/lib/python3.11/dist-packages (0.23.0)\n","Requirement already satisfied: huggingface-hub==0.27.0 in /usr/local/lib/python3.11/dist-packages (0.27.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.31.0) (3.18.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.31.0) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.31.0) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.31.0) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.31.0) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.31.0) (2.32.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.31.0) (0.5.3)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.21.0) (5.9.5)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.15.0) (18.1.0)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.11/dist-packages (from datasets==2.15.0) (0.7)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.15.0) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==2.15.0) (2.2.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==2.15.0) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets==2.15.0) (0.70.15)\n","Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.15.0) (2023.10.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==2.15.0) (3.11.15)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.27.0) (4.14.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.15.0) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.15.0) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.15.0) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.15.0) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.15.0) (6.6.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.15.0) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.15.0) (1.20.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.31.0) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.31.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.31.0) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.31.0) (2025.7.9)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.15.0) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.15.0) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.15.0) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.15.0) (1.17.0)\n","--2025-07-14 02:10:59--  https://huggingface.co/datasets/mit-han-lab/pile-val-backup/resolve/main/val.jsonl.zst\n","Resolving huggingface.co (huggingface.co)... 3.166.152.105, 3.166.152.44, 3.166.152.65, ...\n","Connecting to huggingface.co (huggingface.co)|3.166.152.105|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/64e3d821e5bd41dd0581a1c5/51329de8501ca901993efd894c09760ee0fcf3b4081e2459e32d66c6daa1d6c2?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250714%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250714T021059Z&X-Amz-Expires=3600&X-Amz-Signature=35fcb79c46ceae169d12e9c14a4025c9df16c4d2d1f4a9acda20d6d73a0a981d&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27val.jsonl.zst%3B+filename%3D%22val.jsonl.zst%22%3B&x-id=GetObject&Expires=1752462659&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MjQ2MjY1OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NGUzZDgyMWU1YmQ0MWRkMDU4MWExYzUvNTEzMjlkZTg1MDFjYTkwMTk5M2VmZDg5NGMwOTc2MGVlMGZjZjNiNDA4MWUyNDU5ZTMyZDY2YzZkYWExZDZjMioifV19&Signature=hfY7M5CfFuYWMaHG2Gc8B6u8C%7ELOuVJ88fn%7EIXjTSR7VRk1uvm2ixVDAJQfFnqwu5OXJLYWd9BXz60A5ijr8fWAkH4TNdqczvpJGj0AKHm0nOnnwx8ySafko%7E6c1zgl7Xbnaa7UfE0yF--ArMro8Ox7sbu4VCcfbjSMyeCOhY4XFrZ-C2arvSsEy%7EdZAfzayRmA14il2T3NOCXvQ23clnxcwTVU30p8C8r6MAdW1C2MTHDyFVxhXDJWTdZ8XEU%7ExlgKaIps9dBVg7fzVBzaVYdvKx4gSNrxST2LeqgogcrIlmTewhS-p2r0Nwc7ebnNkyG0dPoouHSrVOe7VNKfvxA__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n","--2025-07-14 02:10:59--  https://cas-bridge.xethub.hf.co/xet-bridge-us/64e3d821e5bd41dd0581a1c5/51329de8501ca901993efd894c09760ee0fcf3b4081e2459e32d66c6daa1d6c2?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250714%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250714T021059Z&X-Amz-Expires=3600&X-Amz-Signature=35fcb79c46ceae169d12e9c14a4025c9df16c4d2d1f4a9acda20d6d73a0a981d&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27val.jsonl.zst%3B+filename%3D%22val.jsonl.zst%22%3B&x-id=GetObject&Expires=1752462659&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MjQ2MjY1OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NGUzZDgyMWU1YmQ0MWRkMDU4MWExYzUvNTEzMjlkZTg1MDFjYTkwMTk5M2VmZDg5NGMwOTc2MGVlMGZjZjNiNDA4MWUyNDU5ZTMyZDY2YzZkYWExZDZjMioifV19&Signature=hfY7M5CfFuYWMaHG2Gc8B6u8C%7ELOuVJ88fn%7EIXjTSR7VRk1uvm2ixVDAJQfFnqwu5OXJLYWd9BXz60A5ijr8fWAkH4TNdqczvpJGj0AKHm0nOnnwx8ySafko%7E6c1zgl7Xbnaa7UfE0yF--ArMro8Ox7sbu4VCcfbjSMyeCOhY4XFrZ-C2arvSsEy%7EdZAfzayRmA14il2T3NOCXvQ23clnxcwTVU30p8C8r6MAdW1C2MTHDyFVxhXDJWTdZ8XEU%7ExlgKaIps9dBVg7fzVBzaVYdvKx4gSNrxST2LeqgogcrIlmTewhS-p2r0Nwc7ebnNkyG0dPoouHSrVOe7VNKfvxA__&Key-Pair-Id=K2L8F4GPSG1IFC\n","Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 18.173.166.85, 18.173.166.82, 18.173.166.5, ...\n","Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|18.173.166.85|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 470907480 (449M)\n","Saving to: â€˜val.jsonl.zstâ€™\n","\n","val.jsonl.zst       100%[===================>] 449.09M  7.92MB/s    in 12s     \n","\n","2025-07-14 02:11:12 (37.5 MB/s) - â€˜val.jsonl.zstâ€™ saved [470907480/470907480]\n","\n"]}],"source":["print('Installing packages...')\n","# !pip install torch transformers==4.31.0 accelerate==0.21.0 sentencepiece==0.1.99 tokenizers==0.13.3 datasets==2.15.0 tqdm zstandard huggingface-hub==0.27.0\n","!curl -L https://huggingface.co/datasets/mit-han-lab/pile-val-backup/resolve/main/val.jsonl.zst -o \"D:\\\\data\\\\val.jsonl.zst\"\n","datapath = \"D:\\\\data\\\\val.jsonl.zst\"\n","import os\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","os.environ[\"HF_HOME\"] = \"D:\\\\data\\\\hf_cache\""]},{"cell_type":"markdown","id":"56475ee1","metadata":{"id":"56475ee1"},"source":["ì‹¤ìŠµì— í•„ìš”í•œ ëª¨ë“ˆì„ ë¡œë“œí•©ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":null,"id":"cfe5330c","metadata":{"id":"cfe5330c"},"outputs":[],"source":["from tqdm import tqdm\n","import torch\n","from torch import nn\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","from datasets import load_dataset\n","from functools import partial\n","import gc\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import Normalize"]},{"cell_type":"markdown","id":"Kq-32KkcyKcM","metadata":{"id":"Kq-32KkcyKcM"},"source":["ë‹¤ìŒ ì½”ë“œëŠ” ëª¨ë¸ í¬ê¸°ë¥¼ ê³„ì‚°í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":null,"id":"32204623","metadata":{"id":"32204623"},"outputs":[],"source":["class LLMModel:\n","    def __init__(self, model_name):\n","        self.model_name = model_name\n","        self.model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=torch.float16, use_safetensors=True)\n","        self.model.eval()\n","\n","        self.tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n","        testenc = load_dataset('wikitext', 'wikitext-2-raw-v1', split='test')\n","        testenc = self.tokenizer(\"\\n\\n\".join(testenc['text']), return_tensors='pt')\n","        self.testenc = testenc.input_ids.to(self.model.device)\n","\n","        self.model_changed = False\n","\n","    def _evaluate(self):\n","        nsamples = 10\n","        nlls = []\n","        for i in tqdm(range(nsamples), desc=\"evaluating...\"):\n","            batch = self.testenc[:, (i * 2048):((i + 1) * 2048)].to(self.model.device)\n","            with torch.no_grad():\n","                lm_logits = self.model(batch).logits\n","            shift_logits = lm_logits[:, :-1, :].contiguous().float()\n","            shift_labels = self.testenc[:, (i * 2048):((i + 1) * 2048)][:, 1:]\n","            loss_fct = nn.CrossEntropyLoss()\n","            loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n","            neg_log_likelihood = loss.float() * 2048\n","            nlls.append(neg_log_likelihood)\n","\n","        return torch.exp(torch.stack(nlls).sum() / (nsamples * 2048))\n","\n","    def get_model_size(self, data_width=16, group_size=-1):\n","        if group_size != -1:\n","            data_width += (16 + 4) / group_size\n","\n","        num_elements = 0\n","        for param in self.model.parameters():\n","            num_elements += param.numel()\n","        return num_elements * data_width\n","\n","    def model_delete(self):\n","        del self.model\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","\n","    def model_evaluate(self, data_width, group_size):\n","        model_perplexity = self._evaluate()\n","        model_size = self.get_model_size(data_width=data_width, group_size=group_size)\n","        print(f\"\\nmodel perplexity: {model_perplexity:.2f}\")\n","        print(f\"model size: {model_size/1024/1024/8:.2f} MiB\")\n","        return model_perplexity\n","\n","    def model_reset(self):\n","        if self.model_changed:\n","            self.model_delete()\n","            self.model = AutoModelForCausalLM.from_pretrained(self.model_name, device_map=\"auto\", torch_dtype=torch.float16, use_safetensors=True)\n","            self.model.eval()\n","            self.model_changed = False\n","\n","    def model_change(self, model: nn.Module):\n","        self.model_delete()\n","        self.model = model\n","        self.model.eval()\n","        self.model_changed = True"]},{"cell_type":"markdown","id":"926ee638","metadata":{"id":"926ee638"},"source":["ë¨¼ì € FP32 ëª¨ë¸ì˜ í˜¼ë€ë„(perflexity)ì™€ ëª¨ë¸ í¬ê¸°ë¥¼ í‰ê°€í•´ë´…ì‹œë‹¤.\n","\n","LLaMA-65B ëª¨ë¸ì˜ ë””ì½”ë”© ë‹¨ê³„ì—ì„œ ë‹¨ì¼ ë°°ì¹˜ ì¶”ë¡ ì„ ìˆ˜í–‰í•  ë•Œ, ìš°ë¦¬ëŠ” $[1, 8192] \\times [8192, 8192]$ í˜•íƒœì˜ GEMV(General Matrix-Vector Multiplication)ì—°ì‚°ì„ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤.\n","\n","NVIDIA A100 80Gì˜ ê²½ìš°, **half-precision(FP16)** ì—ì„œì˜ ì„±ëŠ¥ì€ 312TFLOPSì´ë©°, memory bandwidthëŠ” ì•½ 2000GB/s ì…ë‹ˆë‹¤. ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, **ê³„ì‚° ì§‘ì•½ë„(computation intensity)** ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n","\n","$$\n","\\frac{\\text{FLOP}}{\\text{Byte}} = \\frac{2\\times 8192^2}{8192^2} << \\frac{3.12\\times 10^{11}}{2\\times 10^9}\n","$$\n","\n","ì´ëŠ” ë§¤ìš° ë©”ëª¨ë¦¬ ì œì•½ì (Memory-bounded)(~$10^2$ gap)ìœ¼ë¡œ, ì €ë¹„íŠ¸ ê°€ì¤‘ì¹˜ ì–‘ìí™”ê°€ í•„ìš”í•œ ì´ìœ ì…ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":null,"id":"b723b52b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b723b52b","outputId":"809c64c9-b2f4-4dec-f97e-5f9b759d0e2b","executionInfo":{"status":"ok","timestamp":1752459306640,"user_tz":-540,"elapsed":234331,"user":{"displayName":"ì¡°í˜„ë˜","userId":"14418074065025293504"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","evaluating...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [03:30<00:00, 21.03s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","model perplexity: 28.67\n","model size: 480.08 MiB\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["model_path = \"facebook/opt-125m\"\n","llm_model = LLMModel(model_path)\n","\n","# Evaluate the model\n","llm_model.model_evaluate(data_width=32, group_size=128)"]},{"cell_type":"markdown","id":"2e7e1c7d","metadata":{"id":"2e7e1c7d"},"source":["# 4.1. Weight-only Quantization (AWQ)\n","\n","AWQ (activation aware weight only quantization)"]},{"cell_type":"markdown","id":"61fe61f6","metadata":{"id":"61fe61f6"},"source":["ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ë‹¤ì–‘í•œ ì‘ì—…ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ê³  ìˆì§€ë§Œ, ì—„ì²­ë‚œ ëª¨ë¸ í¬ê¸°ë¡œ ì¸í•´ í•˜ë“œì›¨ì–´ì  ì¥ë²½(ë©”ëª¨ë¦¬ í¬ê¸°)ì´ ë†’ì•„ì§€ê³ , í† í° ìƒì„± ì†ë„ê°€ ëŠë ¤ì§‘ë‹ˆë‹¤(ë©”ëª¨ë¦¬ ëŒ€ì—­í­). LLMì˜ í¬ê¸°ì™€ ê³„ì‚°ëŸ‰ì€ ê¸°í•˜ê¸‰ìˆ˜ì ìœ¼ë¡œ ì¦ê°€í•˜ê³  ìˆëŠ” ë°˜ë©´, ë©”ëª¨ë¦¬ ëŒ€ì—­í­ì€ ëŠë¦¬ê²Œ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ ê²©ì°¨ëŠ” LLM ì„±ëŠ¥ì—ì„œ ì¤‘ìš”í•œ ë³‘ëª© í˜„ìƒì…ë‹ˆë‹¤. ì´ë²ˆ ì‹¤ìŠµì—ì„œëŠ” **ìƒˆë¡œìš´ ì–‘ìí™” ì•Œê³ ë¦¬ì¦˜(AWQ)**ì„ ì‚¬ìš©í•˜ì—¬ LLMì˜ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì´ê³  ì¶”ë¡  ì†ë„ë¥¼ ê°€ì†í™”í•˜ëŠ” ë°©ë²•ì„ íƒêµ¬í•  ê²ƒì…ë‹ˆë‹¤."]},{"cell_type":"markdown","id":"2a9be846","metadata":{"id":"2a9be846"},"source":["## AWQ\n"]},{"cell_type":"markdown","id":"VB2bNIrKySLZ","metadata":{"id":"VB2bNIrKySLZ"},"source":["Uniform quantization ì€ ì‹¤ìˆ˜ ê°’ì„ range $[\\beta, \\alpha]$ì—ì„œ $[0, 2^{b} - 1]$ë¡œ ë§¤í•‘í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n","\n","Notation:\n","\n","- Quantized Weight: $w_q$\n","\n","- Scale factor: $s_q$\n","\n","- Zero Point: $z$\n","\\begin{equation}\n","s_q = \\frac{\\alpha - \\beta}{2^{b} - 1} \\tag{1},\n","\\end{equation}\n","\n","\\begin{equation}\n","z = -\\text{Round}(\\beta * scale) \\tag{2}\n","\\end{equation}\n","\n","\\begin{equation}\n","w_q = \\text{Clamp}(\\text{Round}(\\frac{w}{s_q}) + z) \\tag{3},\n","\\end{equation}\n","\n"]},{"cell_type":"markdown","id":"au0OJ3lV_irH","metadata":{"id":"au0OJ3lV_irH"},"source":["## Pseudo Quantization\n","ì•„ë˜ ì½”ë“œëŠ” ì˜ì‚¬ ì–‘ìí™”(pseudo quantization)ì„ ìœ„í•œ ê²ƒì…ë‹ˆë‹¤.\n","\n","\n","Pseudo QuantizationëŠ” ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì‹¤ì œë¡œ ì–‘ìí™”í•˜ì§€ ì•Šê³ , ì–‘ìí™”ì˜ ì˜í–¥ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤. (ì¦‰, ê°€ì¥ ê°€ê¹Œìš´ ì–‘ìí™”ëœ ê°’ìœ¼ë¡œ ë°˜ì˜¬ë¦¼í•œ ë‹¤ìŒ, **ë‹¤ì‹œ ë¶€ë™ ì†Œìˆ˜ì ìœ¼ë¡œ ë³µì›(dequantizing)í•˜ëŠ”** ê²ƒì…ë‹ˆë‹¤.)"]},{"cell_type":"code","execution_count":null,"id":"d63486a4","metadata":{"id":"d63486a4"},"outputs":[],"source":["# core quantization method (simulated quantization)\n","def pseudo_quantize_tensor(w, n_bit=4, q_group_size=-1):\n","    org_w_shape = w.shape\n","    if q_group_size > 0:\n","        assert org_w_shape[-1] % q_group_size == 0\n","        w = w.reshape(-1, q_group_size)\n","\n","    assert w.dim() == 2\n","\n","    # Calculate the maximum (\\alpha) and minimum values (\\beta) in the tensor.\n","    max_val = w.amax(dim=1, keepdim=True)\n","    assert max_val.dim() == 2 and max_val.size(0) == w.size(0) and max_val.size(1) == 1\n","    min_val = w.amin(dim=1, keepdim=True)\n","    assert min_val.dim() == 2 and min_val.size(0) == w.size(0) and min_val.size(1) == 1\n","\n","    # Calculate the scale factor and zero point.  (Formula 1 & 2)\n","    max_int = 2 ** n_bit - 1\n","    scales = (max_val - min_val).clamp(min=1e-5) / max_int\n","    assert scales.shape == max_val.shape\n","    zeros = (-torch.round(min_val / scales)).clamp_(0, max_int)\n","    assert scales.shape == min_val.shape\n","\n","    assert torch.isnan(scales).sum() == 0\n","    assert torch.isnan(w).sum() == 0\n","\n","    # Quantize W: Map values in the range [\\beta, \\alpha] to lie within [0, 2^b - 1] (Formula 3)\n","    w = torch.clamp(torch.round(w / scales) + zeros, 0, max_int)\n","    assert w.dim() == 2 and w.size(0) == scales.size(0) and w.size(1) == q_group_size\n","\n","    # Dequantize W (pseudo quantization, the inverse transformation of Formula 3)\n","    w = (w - zeros) * scales\n","    assert w.dim() == 2 and w.size(0) == scales.size(0) and w.size(1) == q_group_size\n","\n","    assert torch.isnan(w).sum() == 0\n","\n","    w = w.reshape(org_w_shape)\n","    return w\n","\n","@torch.no_grad()\n","def pseudo_quantize_model_weight(\n","    model, w_bit, q_group_size,\n","):\n","    for n, m in model.named_modules():\n","        if isinstance(m, nn.Linear):\n","            m.weight.data = pseudo_quantize_tensor(m.weight.data, n_bit=w_bit, q_group_size=q_group_size)"]},{"cell_type":"markdown","id":"hU8nK-JY0iKA","metadata":{"id":"hU8nK-JY0iKA"},"source":["ì´ì œ quantized 3-bit ëª¨ë¸ì˜ í˜¼ë€ë„(perplexity)ì™€ í¬ê¸°ë¥¼ í‰ê°€í•´ ë´…ì‹œë‹¤."]},{"cell_type":"code","execution_count":null,"id":"fc985610","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fc985610","outputId":"1c90d3f2-3d31-4a60-afac-89b9a471a409","executionInfo":{"status":"ok","timestamp":1752459510353,"user_tz":-540,"elapsed":203666,"user":{"displayName":"ì¡°í˜„ë˜","userId":"14418074065025293504"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["evaluating...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [03:20<00:00, 20.08s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","model perplexity: 64.91\n","model size: 47.12 MiB\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["llm_model.model_reset()\n","pseudo_quantize_model_weight(llm_model.model, w_bit=3, q_group_size=128)\n","llm_model.model_changed = True\n","\n","# Evaluate the model\n","llm_model.model_evaluate(data_width=3, group_size=128)"]},{"cell_type":"markdown","id":"KrDoPrp7Ncma","metadata":{"id":"KrDoPrp7Ncma"},"source":["ëª¨ë¸ í¬ê¸°ê°€ ì¤„ì–´ë“  ê²ƒì€ í™•ì¸í•  ìˆ˜ ìˆì§€ë§Œ, í˜¼ë€ë„(perplexity)ëŠ” ìƒë‹¹íˆ ì¦ê°€í–ˆìŠµë‹ˆë‹¤."]},{"cell_type":"markdown","id":"-BAC3SPY0swu","metadata":{"id":"-BAC3SPY0swu"},"source":["ë…¼ë¬¸ì—ì„œì˜ ê´€ì°°ì— ë”°ë¥´ë©´ LLMì˜ í™œì„±í™”(activations)ì—ì„œ ì¼ë¶€ ì±„ë„ì— **ì•„ì›ƒë¼ì´ì–´(outliers)**ê°€ ì†ŒëŸ‰ ë°œìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤. íŠ¹ì • ì±„ë„ì— ì•„ì›ƒë¼ì´ì–´ê°€ ìˆëŠ” ê²½ìš°, ì´ëŠ” **ëª¨ë“  í† í°ì—ì„œ ì§€ì†ì ìœ¼ë¡œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.**\n","\n","ì£¼ì–´ì§„ í† í°ì— ëŒ€í•œ ì±„ë„ ê°„ì˜ ë¶„ì‚°(variance)ì€ í¬ì§€ë§Œ(ì¼ë¶€ ì±„ë„ì˜ í™œì„±í™”ëŠ” ë§¤ìš° í¬ê³ , ëŒ€ë¶€ë¶„ì€ ì‘ìŠµë‹ˆë‹¤), íŠ¹ì • ì±„ë„ì˜ í¬ê¸°(magnitude)ê°€ í† í° ê°„ì— ê°€ì§€ëŠ” ë¶„ì‚°ì€ ì‘ìŠµë‹ˆë‹¤(ì•„ì›ƒë¼ì´ì–´ ì±„ë„ì€ ì§€ì†ì ìœ¼ë¡œ í½ë‹ˆë‹¤).\n","\n","\n","AWQ(Activation Aware Weight Quantization)ì˜ ê¸°ë²•ì— ë”°ë¥´ë©´, í™œì„±í™”(activation) ì•„ì›ƒë¼ì´ì–´ì— í•´ë‹¹í•˜ëŠ” ê°€ì¤‘ì¹˜ ì±„ë„ì€ ë” ë‘ë“œëŸ¬ì§€ë©°, ì´ëŸ¬í•œ ë‘ë“œëŸ¬ì§„ ê°€ì¤‘ì¹˜ë¥¼ ë³´ì¡´í•˜ëŠ” ê²ƒì´ ì„±ëŠ¥ í–¥ìƒìœ¼ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ìŒìœ¼ë¡œ, ë‘ë“œëŸ¬ì§„ ê°€ì¤‘ì¹˜ë¥¼ ì°¾ê³  ì›ë˜ ê°’ìœ¼ë¡œ ìœ ì§€í•˜ì—¬ í˜¼ë€ë„(perplexity)ì˜ ë³€í™”ë¥¼ ê´€ì°°í•´ ë³´ê² ìŠµë‹ˆë‹¤.\n","\n","ì•„ë˜ ì½”ë“œëŠ” calibration ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ì—¬ í™œì„±í™” ì•„ì›ƒë¼ì´ì–´ë¥¼ ì–»ê³  ë‘ë“œëŸ¬ì§„ ê°€ì¤‘ì¹˜ë¥¼ ì‹ë³„í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":null,"id":"fb52620d","metadata":{"id":"fb52620d"},"outputs":[],"source":["def get_calib_dataset(tokenizer=None, n_samples=256, block_size=512):\n","    dataset = load_dataset(\"mit-han-lab/pile-val-backup\", split=\"validation\")\n","    dataset = dataset.shuffle(seed=42)\n","    samples = []\n","    n_run = 0\n","    for data in dataset:\n","        line = data[\"text\"]\n","        line = line.strip()\n","        line_encoded = tokenizer.encode(line)\n","        if len(line_encoded) > block_size:\n","            continue\n","        sample = torch.tensor([line_encoded])\n","        if sample.numel() == 0:\n","            continue\n","        samples.append(sample)\n","        n_run += 1\n","        if n_run == n_samples:\n","            break\n","\n","    # now concatenate all samples and split according to block size\n","    cat_samples = torch.cat(samples, dim=1)\n","    n_split = cat_samples.shape[1] // block_size\n","    print(f\" * Split into {n_split} blocks\")\n","    return [cat_samples[:, i*block_size:(i+1)*block_size] for i in range(n_split)]\n","\n","@torch.no_grad()\n","def get_calib_feat(model, tokenizer):\n","    input_dict = dict()\n","    def stat_input_max_hook(m, x, y, name):\n","        if isinstance(x, tuple):\n","            x = x[0]\n","        x_max = x.view(-1, x.shape[-1]).abs().mean(dim=0).cpu().detach()\n","        if name not in input_dict:\n","            input_dict[name] = [x_max]\n","        else:\n","            input_dict[name] += [x_max]\n","\n","    hooks = []\n","    for name, m in model.named_modules():\n","        if isinstance(m, nn.Linear):\n","            hooks.append(\n","                m.register_forward_hook(\n","                    partial(stat_input_max_hook, name=name)))\n","\n","    print(\"Collecting activation scales...\")\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    samples = get_calib_dataset(tokenizer)\n","    pbar = tqdm(samples)\n","    for input_ids in pbar:\n","        input_ids = input_ids.to(device)\n","        model(input_ids)\n","\n","    for hook in hooks:\n","        hook.remove()\n","    return input_dict"]},{"cell_type":"code","execution_count":null,"id":"bfd04606","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bfd04606","outputId":"b2d83bf2-5efc-4178-e29e-5586316279e5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting activation scales...\n"]},{"output_type":"stream","name":"stderr","text":["Repo card metadata block was not found. Setting CardData to empty.\n","WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"]},{"output_type":"stream","name":"stdout","text":[" * Split into 127 blocks\n"]},{"output_type":"stream","name":"stderr","text":[" 32%|â–ˆâ–ˆâ–ˆâ–      | 41/127 [01:54<04:38,  3.24s/it]"]}],"source":["llm_model.model_reset()\n","input_feat = get_calib_feat(llm_model.model, llm_model.tokenizer)"]},{"cell_type":"code","execution_count":null,"id":"X_pPpL0FGful","metadata":{"id":"X_pPpL0FGful"},"outputs":[],"source":["print(type(input_feat['model.decoder.layers.0.self_attn.q_proj']))\n","print(len(input_feat['model.decoder.layers.0.self_attn.q_proj']))\n","print(input_feat['model.decoder.layers.0.self_attn.q_proj'][0].shape)\n","print(sum(input_feat['model.decoder.layers.0.self_attn.q_proj']).shape)"]},{"cell_type":"markdown","id":"h5GGLwczKghz","metadata":{"id":"h5GGLwczKghz"},"source":["# [ì‹¤ìŠµ 1] Scale 1% salient channels\n","\n","1%ì˜ ê°€ì¤‘ì¹˜ë¥¼ FP16ìœ¼ë¡œ ìœ ì§€í•˜ë©´ ëª¨ë¸ í¬ê¸°(ì´ ë¹„íŠ¸ ìˆ˜ë¡œ ì¸¡ì •)ë¥¼ í¬ê²Œ ëŠ˜ë¦¬ì§€ ì•Šê³ ë„ ì–‘ìí™” ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆì§€ë§Œ, ì´ëŸ¬í•œ í˜¼í•© ì •ë°€ë„ ë°ì´í„° ìœ í˜•ì€ ì‹œìŠ¤í…œ êµ¬í˜„ì„ ì–´ë µê²Œ ë§Œë“­ë‹ˆë‹¤.\n","\n","ë”°ë¼ì„œ ì¤‘ìš”í•œ ê°€ì¤‘ì¹˜ë¥¼ ì‹¤ì œë¡œ FP16ìœ¼ë¡œ ìœ ì§€í•˜ì§€ ì•Šê³  ì¤‘ìš”í•œ ê°€ì¤‘ì¹˜ë¥¼ ë³´í˜¸í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤."]},{"cell_type":"markdown","id":"srM0CaQw3xyc","metadata":{"id":"srM0CaQw3xyc"},"source":["AWQì˜ ë°©ë²•ë¡ ì— ë”°ë¥´ë©´, ì¤‘ìš”í•œ ê°€ì¤‘ì¹˜ ì±„ë„ì„ ë‹¨ìˆœíˆ ìŠ¤ì¼€ì¼ë§í•˜ì—¬(íŠ¹ì •í•œ ê°’ì„ ê³±í•´ ì£¼ì–´) ë³´í˜¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì›ë¦¬ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n","\n","- Linear layer channel $\\mathbf{y} = \\mathbf{w}x$ (from $\\mathbf{W}x$)ì¼ ë•Œ, ìš°ë¦¬ê°€ ì£¼ëª©í•´ì•¼ í•  ê²ƒì€ ì–‘ìí™” í•¨ìˆ˜ $Q(\\mathbf{w})x$ìœ¼ë¡œ ë°œìƒí•˜ëŠ” quantization errorì…ë‹ˆë‹¤.\n","\n","- Quantization function $Q(\\mathbf{w})$ = $Î”\\cdot Round(\\frac{\\mathbf{w}}{Î”})$, $Î” = \\frac{\\max(|w|)}{2^{N - 1}}$.\n","\n","- Quantization error $Err(Q(\\mathbf{w}) x) = Î”\\cdot RoundErr(\\frac{\\mathbf{w}}{Î”})\\cdot x$\n","- ìŠ¤ì¼€ì¼ë§ ëœ  Quantization error $Err(Q(\\mathbf{w} \\cdot s)(\\frac{x}{s})) = Î”\\cdot RoundErr(\\frac{\\mathbf{w}}{Î”})\\cdot x\\cdot \\mathbf{\\frac{1}{s}}$.\n","- $RoundErr$ ëŠ” ì–¸ì œë‚˜ ~0.25 ì…ë‹ˆë‹¤ (0-0.5 ì‚¬ì´ì˜ í‰ê· ì´ë¯€ë¡œ).\n","- ê·¸ë£¹ì˜ í¬ê¸°ê°€ ì¶©ë¶„íˆ í´ ë•Œ(e.g., 128), í•˜ë‚˜ì˜ ì±„ë„ì„ ìŠ¤ì¼€ì¼ë§í•˜ëŠ” ê²ƒì€ ì¼ë°˜ì ìœ¼ë¡œ ê·¸ë£¹ ë‚´ ìµœëŒ€ ê°’ì„ ì¦ê°€ì‹œí‚¤ì§€ ì•ŠìŠµë‹ˆë‹¤ (ì¦‰, $Î”$ ëŠ” ë³€í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤).\n","- ê·¸ëŸ¬ë¯€ë¡œ, $Err(Q(\\mathbf{w} \\cdot s)(\\frac{x}{s})) = Î”\\cdot RoundErr(\\frac{\\mathbf{w}}{Î”})\\cdot x\\cdot \\mathbf{\\frac{1}{s}}$ < $Î”\\cdot RoundErr(\\frac{\\mathbf{w}}{Î”})\\cdot x = Err(Q(\\mathbf{w}) x)$.\n","\n","ì•„ë˜ ì½”ë“œë¥¼ ì™„ì„±í•˜ì—¬ ì¤‘ìš”í•œ ê°€ì¤‘ì¹˜ ì±„ë„ì„ ìŠ¤ì¼€ì¼ë§í•˜ê³ , ì–‘ìí™” í•œ ë‹¤ìŒ, ë‹¤ì‹œ ìŠ¤ì¼€ì¼ì„ ì¤„ì¸ í›„ í˜¼ë€ë„(perplexity)ì˜ ë³€í™”ë¥¼ ê´€ì°°í•´ë³´ì„¸ìš”."]},{"cell_type":"code","execution_count":null,"id":"TdO4KtnsNKf5","metadata":{"id":"TdO4KtnsNKf5"},"outputs":[],"source":["@torch.no_grad()\n","def pseudo_quantize_model_weight_scaleup(\n","    model, w_bit, q_group_size, input_feat, scale_factor\n","):\n","    for n, m in model.named_modules():\n","        if isinstance(m, nn.Linear):\n","            importance = sum(input_feat[n]).float()\n","            # 1í¼ì„¼íŠ¸ ì±„ë„ì˜ ê°œìˆ˜\n","            num_samples = int(len(importance) * 0.01)\n","\n","            ############### YOUR CODE STARTS HERE ###############\n","\n","            # Step 1: importanceë¥¼ ê¸°ì¤€ìœ¼ë¡œ 1%ì˜ ì¤‘ìš”í•œ ì±„ë„ì„ ì°¾ìœ¼ì„¸ìš”  (hint: use torch.topk())\n","            # hint : torch.topk() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. torch.topk() í•¨ìˆ˜ëŠ” PyTorchì—ì„œ í…ì„œì˜ ê°’ ì¤‘ ìƒìœ„ kê°œì˜ ê°’ê³¼ ê·¸ë“¤ì˜ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤. torch.topk()[0]ëŠ” ê°’ì„, torch.topk()[1]ì€ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n","            outlier_mask = torch.topk(importance, int(len(importance) * 0.01))[1]\n","\n","            ############### YOUR CODE ENDS HERE #################\n","            assert outlier_mask.dim() == 1\n","\n","            # ìŠ¤ì¼€ì¼ íŒ©í„°ë¥¼ ì ìš©í•˜ëŠ” ê²ƒì„ ì‹œë®¬ë ˆì´ì…˜í•˜ê¸° ìœ„í•´, ì–‘ìí™” ì „ì— ìŠ¤ì¼€ì¼ íŒ©í„°ë¥¼ ê³±í•˜ê³ , ì–‘ìí™” í›„ì— ìŠ¤ì¼€ì¼ íŒ©í„°ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.\n","            # scale_factorë¥¼ ì´ìš©í•´ ì¤‘ìš”í•œ ê°€ì¤‘ì¹˜ ì±„ë„ì˜ ê°’ì„ í™•ëŒ€í•©ë‹ˆë‹¤.\n","            m.weight.data[:, outlier_mask] *= scale_factor\n","\n","            m.weight.data = pseudo_quantize_tensor(m.weight.data, n_bit=w_bit, q_group_size=q_group_size)\n","\n","            ############### YOUR CODE STARTS HERE ###############\n","\n","            # Step 2: scale_factorë¥¼ ì´ìš©í•´ ì¤‘ìš”í•œ ê°€ì¤‘ì¹˜ ì±„ë„ì˜ ê°’ì„ ë‹¤ì‹œ ì¶•ì†Œí•˜ì„¸ìš”.\n","            m.weight.data[:, outlier_mask] /= scale_factor\n","\n","            ############### YOUR CODE ENDS HERE #################"]},{"cell_type":"code","execution_count":null,"id":"GoTh5CzuPhtV","metadata":{"id":"GoTh5CzuPhtV"},"outputs":[],"source":["llm_model.model_reset()\n","pseudo_quantize_model_weight_scaleup(llm_model.model, w_bit=3, q_group_size=128, input_feat=input_feat, scale_factor=2)\n","llm_model.model_changed = True\n","\n","# Evaluate the model\n","llm_model.model_evaluate(data_width=3, group_size=128)"]},{"cell_type":"markdown","id":"ffc63e22","metadata":{"id":"ffc63e22"},"source":["ìŠ¤ì¼€ì¼ë§ì„ í†µí•´ì„œ ì¤‘ìš”í•œ ê°€ì¤‘ì¹˜ë¥¼ ë³´í˜¸í•¨ê³¼ ë™ì‹œì—, ëª¨ë“  ê°€ì¤‘ì¹˜ë¥¼ 3bitë¡œ ìœ ì§€í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤."]},{"cell_type":"code","execution_count":null,"id":"4SBUNQc_MDcP","metadata":{"id":"4SBUNQc_MDcP"},"outputs":[],"source":["for scale_factor in [1,2,3,4]:\n","    llm_model.model_reset()\n","    pseudo_quantize_model_weight_scaleup(llm_model.model, w_bit=3, q_group_size=128, input_feat=input_feat, scale_factor=scale_factor)\n","    llm_model.model_changed = True\n","\n","    # Evaluate the model\n","    print(f\"scale_factor={scale_factor}\")\n","    llm_model.model_evaluate(data_width=3, group_size=128)"]},{"cell_type":"markdown","id":"kDIYt2xJEt84","metadata":{"id":"kDIYt2xJEt84"},"source":["ì½”ë“œì—ì„œ ì„œë¡œ ë‹¤ë¥¸ ìŠ¤ì¼€ì¼ë§ íŒ©í„° $s$(ì˜ˆ: 1, 2, 3, 4)ë¥¼ ì‹œë„í•˜ê³  í˜¼ë€ë„(perplexity)ì˜ ë³€í™”ë¥¼ ê´€ì°°í•´ë³´ì„¸ìš”.\n","\n","í˜¼ë€ë„(perplexity)ê°€ ë¨¼ì € ê°ì†Œí•˜ë‹¤ê°€ ë‹¤ì‹œ ì¦ê°€í•˜ëŠ” ê²ƒì„ ê´€ì°°í–ˆë‚˜ìš”?\n","\n","ë„ˆë¬´ í° íŒ©í„°ë¡œ ìŠ¤ì¼€ì¼ë§í•˜ë©´ ê·¸ë£¹ ë‚´ ìµœëŒ€ ê°’ì´ ì¦ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤(ì¦‰,$Î”$ê°€ ì¦ê°€í•¨).\n","\n","ì´ëŠ” ë‹¤ë¥¸ ì±„ë„ì˜ ì–‘ìí™”ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤."]},{"cell_type":"markdown","id":"ueFx8RCHF2zu","metadata":{"id":"ueFx8RCHF2zu"},"source":["# [ì‹¤ìŠµ 2] Scale factor search\n","\n","ì§€ê¸ˆê¹Œì§€ ìš°ë¦¬ëŠ” ìŠ¤ì¼€ì¼ë§ íŒ©í„°$s$ë¥¼ ì§ì ‘ ì •ì˜í•´ ì£¼ì—ˆìŠµë‹ˆë‹¤.\n","\n","ê·¸ëŸ¬ë‚˜ Fine-tuningì˜ ë¶ˆì•ˆì •ì„± ë•Œë¬¸ì—, ë¯¸ë¦¬ ì •ì˜ëœ ê²€ìƒ‰ ê³µê°„ ë‚´ì—ì„œ ìµœì ì˜\n","$s$ë¥¼ ì°¾ëŠ” ê²ƒì´ ë” ë‚˜ì€ ì„ íƒì´ ë  ê²ƒì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì¤‘ìš”í•œ ê°€ì¤‘ì¹˜ë¥¼ ë³´í˜¸í•˜ë©´ì„œ ë‹¤ë¥¸ ê°’ì„ ê³ ë ¤í•˜ê¸° ìœ„í•´ ê²€ìƒ‰ ê³µê°„ ë‚´ì—ì„œ ìµœì ì˜ ìŠ¤ì¼€ì¼ì„ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","\n","ì‹¤ì œë¡œ, ë…¼ë¬¸ì—ì„œëŠ” í™œì„±í™”ë§Œ ê³ ë ¤í•˜ëŠ” ê²ƒìœ¼ë¡œë„ ì¢‹ì€ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŒì„ ê´€ì°°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","\n","ìš°ë¦¬ëŠ” ìŠ¤ì¼€ì¼ë§ íŒ©í„° $s$ë¥¼ í™œì„±í™”ì˜ L1-norm (ì¦‰, acviation matrixì˜ ì ˆëŒ“ê°’ë“¤ì˜ í‰ê· )ì˜ $\\alpha$ì œê³±ìœ¼ë¡œ ì„¤ì •í•  ê²ƒì…ë‹ˆë‹¤.\n","\n","$\\alpha$ì˜ ê°’ì€ grid searchë¥¼ í†µí•´ ì ì ˆí•œ ê°’ìœ¼ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n","\n","ê²€ìƒ‰ì„ ìœ„í•œ ì½”ë“œë¥¼ ì¶”ê°€í•˜ê³  ì‹¤í–‰í•˜ì—¬ í˜¼ë€ë„(perplexity)ë¥¼ ê´€ì°°í•˜ì„¸ìš”."]},{"cell_type":"markdown","id":"bA4b4L2OL05N","metadata":{"id":"bA4b4L2OL05N"},"source":["$$\n","ğ‹(\\mathbf{s})=\\lVert Q(\\mathbf{W}\\cdot \\mathbf{s})  (\\mathbf{s^{-1}} \\cdot \\mathbf{X}) - \\mathbf{W}\\mathbf{X}  \\rVert,  \\quad\\mathbf{s}= \\mathbf{s_X}^{\\alpha},  \\mathbf{s_X} = \\|X\\|_1\n","$$\n","$$\n","\\mathbf{s}^* = \\text{argmin}_{\\mathbf{s}} ğ‹(\\mathbf{s}),\\quad \\alpha^*=\\text{argmin}_{\\alpha} ğ‹(\\mathbf{s_X}^{\\alpha})\n","$$"]},{"cell_type":"code","execution_count":null,"id":"ff_sv6k0R2Eb","metadata":{"id":"ff_sv6k0R2Eb"},"outputs":[],"source":["@torch.no_grad()\n","def scale_ln_fcs(ln, fcs, scales):\n","    if not isinstance(fcs, list):\n","        fcs = [fcs]\n","\n","    scales = scales.to(ln.weight.device)\n","\n","    ln.weight.div_(scales)\n","    if hasattr(ln, 'bias') and ln.bias is not None:\n","        ln.bias.div_(scales)\n","\n","    for fc in fcs:\n","        fc.weight.mul_(scales.view(1, -1))\n","\n","    for p in ln.parameters():\n","        assert torch.isnan(p).sum() == 0\n","    for fc in fcs:\n","        for p in fc.parameters():\n","            assert torch.isnan(p).sum() == 0\n","\n","\n","@torch.no_grad()\n","def scale_fc_fc(fc1, fc2, scales):\n","    assert isinstance(fc1, nn.Linear)\n","    assert isinstance(fc2, nn.Linear)\n","\n","    scales = scales.to(fc1.weight.device)\n","\n","    # fc1.weight.div_(scales.view(-1, 1))\n","    fc1.weight[-scales.size(0):].div_(scales.view(-1, 1))\n","    if fc1.bias is not None:\n","        fc1.bias.div_(scales.view(-1))\n","\n","    fc2.weight.mul_(scales.view(1, -1))\n","\n","    for p in fc1.parameters():\n","        assert torch.isnan(p).sum() == 0\n","    for p in fc2.parameters():\n","        assert torch.isnan(p).sum() == 0\n","\n","@torch.no_grad()\n","def auto_scale_block(module, name, w_bit,\n","                     q_group_size,\n","                     input_feat):\n","\n","    # find the best scale ratio\n","    def _search_module_scale(block, linears2scale: list, x, kwargs={}):\n","\n","        x = x.to(next(block.parameters()).device)\n","        with torch.no_grad():\n","            org_out = block(x, **kwargs)\n","            if isinstance(org_out, tuple):\n","                org_out = org_out[0]\n","\n","        s_x = x.view(-1, x.shape[-1]).abs().mean(0)\n","        s_x = torch.clamp(s_x, 1e-5)\n","\n","\n","        # Step 1: best_error, best_ratio, ë° best_scalesë¥¼ ì´ˆê¸°í™”\n","        best_error = torch.inf\n","        best_ratio = -1\n","        best_scales = 0\n","\n","\n","        n_grid = 20\n","        history = []\n","\n","        org_sd = {k: v.cpu() for k, v in block.state_dict().items()}\n","        for ratio in range(n_grid):\n","            # ratio is the \\alpha in the formula\n","            ratio = ratio * 1 / n_grid\n","\n","            ############### YOUR CODE STARTS HERE ###############\n","\n","            # Step 2: ê³µì‹ì— ë”°ë¼ ìŠ¤ì¼€ì¼ ê³„ì‚°\n","            scales = s_x ** ratio\n","\n","            ############### YOUR CODE ENDS HERE #################\n","            assert scales.shape == s_x.shape\n","\n","            scales = scales / (scales.max() * scales.min()).sqrt().view(1, -1)\n","\n","            for fc in linears2scale:\n","\n","                scales = scales.to(fc.weight.device)\n","\n","                # scale_factorë¥¼ ì´ìš©í•´ ì¤‘ìš”í•œ ê°€ì¤‘ì¹˜ ì±„ë„ì˜ ê°’ì„ í™•ëŒ€í•©ë‹ˆë‹¤.\n","                fc.weight.mul_(scales)\n","\n","                fc.weight.data = pseudo_quantize_tensor(fc.weight.data, w_bit, q_group_size)\n","\n","                ############### YOUR CODE STARTS HERE ###############\n","\n","                # Step 3: scale_factorë¥¼ ì´ìš©í•´ ì¤‘ìš”í•œ ê°€ì¤‘ì¹˜ ì±„ë„ì˜ ê°’ì„ ë‹¤ì‹œ ì¶•ì†Œí•˜ì„¸ìš”.\n","                fc.weight.data /= scales\n","\n","                ############### YOUR CODE ENDS HERE #################\n","\n","            out = block(x, **kwargs)\n","            if isinstance(out, tuple):\n","                out = out[0]\n","\n","            loss = (org_out - out).float().pow(2).mean().item()  # float prevents overflow\n","            history.append(loss)\n","            is_best = loss < best_error\n","            if is_best:\n","                best_error = loss\n","                best_ratio = ratio\n","                best_scales = scales\n","            block.load_state_dict(org_sd)\n","\n","        if best_ratio == -1:\n","            print(history)\n","            raise Exception\n","\n","        best_scales = best_scales.view(-1)\n","\n","        assert torch.isnan(best_scales).sum() == 0, best_scales\n","        return best_scales.detach()\n","\n","    # attention input\n","    inp = input_feat[name + '.self_attn.out_proj']\n","    inp = torch.cat([x.unsqueeze(0) for x in inp], dim=0).unsqueeze(0)\n","    qkv = [module.self_attn.q_proj, module.self_attn.k_proj, module.self_attn.v_proj]\n","    final_scales = _search_module_scale(module.self_attn, qkv, inp)\n","    scale_ln_fcs(module.self_attn_layer_norm, qkv, final_scales)\n","\n","    # attn out\n","    inp = input_feat[name + '.self_attn.out_proj']\n","    inp = torch.cat([x.unsqueeze(0) for x in inp], dim=0)\n","    final_scales = _search_module_scale(module.self_attn.out_proj, [module.self_attn.out_proj], inp)\n","    scale_fc_fc(module.self_attn.v_proj, module.self_attn.out_proj, final_scales)\n","\n","    # fc1\n","    inp = input_feat[name + '.fc1']\n","    inp = torch.cat([x.unsqueeze(0) for x in inp], dim=0)\n","    final_scales = _search_module_scale(module.fc1, [module.fc1], inp)\n","    scale_ln_fcs(module.final_layer_norm, module.fc1, final_scales)\n","\n","    # fc2\n","    inp = input_feat[name + '.fc2']\n","    inp = torch.cat([x.unsqueeze(0) for x in inp], dim=0)\n","    final_scales = _search_module_scale(module.fc2, [module.fc2], inp)\n","    scale_fc_fc(module.fc1, module.fc2, final_scales)\n","\n","@torch.no_grad()\n","def pseudo_quantize_model_weight_auto_scale(\n","    model, w_bit, q_group_size, input_feat\n","):\n","    from transformers.models.opt.modeling_opt import OPTDecoderLayer\n","\n","    for name, module in model.named_modules():\n","        if isinstance(module, OPTDecoderLayer):\n","            auto_scale_block(module, name, w_bit, q_group_size, input_feat)\n","\n","    for n, m in model.named_modules():\n","        if isinstance(m, nn.Linear):\n","            m.weight.data = pseudo_quantize_tensor(m.weight.data, n_bit=w_bit, q_group_size=q_group_size)"]},{"cell_type":"code","execution_count":null,"id":"cXuQUykZMdKa","metadata":{"id":"cXuQUykZMdKa"},"outputs":[],"source":["llm_model.model_reset()\n","pseudo_quantize_model_weight_auto_scale(llm_model.model, w_bit=3, q_group_size=128, input_feat=input_feat)\n","llm_model.model_changed = True\n","\n","# Evaluate and delete the model\n","llm_model.model_evaluate(data_width=3, group_size=128)"]},{"cell_type":"markdown","id":"c8edb0c1","metadata":{"id":"c8edb0c1"},"source":["# 4.2. Weight and Activation Quantization"]},{"cell_type":"markdown","id":"60ae31c3","metadata":{"id":"60ae31c3"},"source":["ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ë‹¤ì–‘í•œ ì‘ì—…ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ê³  ìˆì§€ë§Œ, ì—„ì²­ë‚œ ëª¨ë¸ í¬ê¸°ë¡œ ì¸í•´ í•˜ë“œì›¨ì–´ì  ì¥ë²½(ë©”ëª¨ë¦¬ í¬ê¸°)ì´ ë†’ì•„ì§€ê³ , í† í° ìƒì„± ì†ë„ê°€ ëŠë ¤ì§‘ë‹ˆë‹¤(ë©”ëª¨ë¦¬ ëŒ€ì—­í­). LLMì˜ í¬ê¸°ì™€ ê³„ì‚°ëŸ‰ì€ ê¸°í•˜ê¸‰ìˆ˜ì ìœ¼ë¡œ ì¦ê°€í•˜ê³  ìˆëŠ” ë°˜ë©´, ë©”ëª¨ë¦¬ ëŒ€ì—­í­ì€ ëŠë¦¬ê²Œ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ ê²©ì°¨ëŠ” LLM ì„±ëŠ¥ì—ì„œ ì¤‘ìš”í•œ ë³‘ëª© í˜„ìƒì…ë‹ˆë‹¤. ì´ë²ˆ ì‹¤ìŠµì—ì„œëŠ” **ìƒˆë¡œìš´ ì–‘ìí™” ì•Œê³ ë¦¬ì¦˜(AWQ)**ì„ ì‚¬ìš©í•˜ì—¬ LLMì˜ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì´ê³  ì¶”ë¡  ì†ë„ë¥¼ ê°€ì†í™”í•˜ëŠ” ë°©ë²•ì„ íƒêµ¬í•  ê²ƒì…ë‹ˆë‹¤."]},{"cell_type":"markdown","id":"235839a0","metadata":{"id":"235839a0"},"source":["ì´ì „ ìˆ˜ì—…ì—ì„œëŠ” ì–‘ìí™”(Quantization)ì˜ ê¸°ë³¸ ë°©ë²•ë“¤ì„ ë°°ì› ìŠµë‹ˆë‹¤.\n","\n","ì–‘ìí™”ì—ëŠ” ë‘ ê°€ì§€ ìœ í˜•ì´ ìˆìŠµë‹ˆë‹¤:\n","\n","- ê°€ì¤‘ì¹˜(weight)ì™€ í™œì„±í™”(activation) ëª¨ë‘ ì–‘ìí™”\n","    - ê³„ì‚° í•œê³„ê°€ ìˆëŠ” ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ë” ìœ ë¦¬í•©ë‹ˆë‹¤: ì˜ˆë¥¼ ë“¤ì–´ ì»¨í…ìŠ¤íŠ¸ ë‹¨ê³„ë‚˜ ëŒ€ê·œëª¨ ë°°ì¹˜ ì¶”ë¡ \n","    - ì˜ˆì‹œ: SmoothQuant(W8A8 quantization)\n","- ê°€ì¤‘ì¹˜(weight)ë§Œ ì–‘ìí™”\n","    - ë©”ëª¨ë¦¬ í•œê³„ê°€ ìˆëŠ” ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ë” ìœ ë¦¬í•©ë‹ˆë‹¤: ì˜ˆë¥¼ ë“¤ì–´ ë””ì½”ë”© ë‹¨ê³„ë‚˜ ë‹¨ì¼ ë°°ì¹˜ ì¶”ë¡ .\n","    - ì˜ˆì‹œ: AWQ(W4A16 quantization)"]},{"cell_type":"markdown","id":"be754200","metadata":{"id":"be754200"},"source":["ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” OPT-125m ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ SmoothQuantê°€ ê°€ì¤‘ì¹˜ì™€ í™œì„±í™” ëª¨ë‘ì— 8ë¹„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ FP16 ëª¨ë¸ê³¼ ë™ì¼í•œ ì •í™•ë„ë¥¼ ë‹¬ì„±í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. SmoothQuantëŠ” Linear layerì—ì„œ ì™„ì „í•œ INT8 GEMMì„ ê°€ëŠ¥í•˜ê²Œ í•˜ê³ , ì´ìƒê°’ì„ ë‚˜íƒ€ë‚´ê¸° ìœ„í•´ ê³ ì •ë°€ë„ ìˆ«ìë¥¼ ìš”êµ¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."]},{"cell_type":"code","execution_count":null,"id":"cce38d88","metadata":{"id":"cce38d88"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","from transformers.models.opt.modeling_opt import OPTDecoderLayer\n","from transformers.models.bloom.modeling_bloom import BloomBlock\n","from transformers.models.llama.modeling_llama import LlamaDecoderLayer, LlamaRMSNorm"]},{"cell_type":"markdown","id":"f061090a","metadata":{"id":"f061090a"},"source":["Uniform quantization ì€ ì‹¤ìˆ˜ ê°’ì„ range$[\\beta, \\alpha]$ì—ì„œ $[0, 2^{b} - 1]$ë¡œ ë§¤í•‘í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n","\n","Notation:\n","\n","- Quantized Weight: $w_q$\n","\n","- Scale factor: $s_q$\n","\n","- Zero Point: $z$\n","\\begin{equation}\n","s_q = \\frac{\\alpha - \\beta}{2^{b} - 1} \\tag{1},\n","\\end{equation}\n","\\begin{equation}\n","z = -\\text{Round}(\\beta * scale) \\tag{2}\n","\\end{equation}\n","\\begin{equation}\n","w_q = \\text{Clamp}(\\text{Round}(\\frac{w}{s_q}) + z) \\tag{3},\n","\\end{equation}\n","\n"]},{"cell_type":"markdown","id":"fd8dafc5","metadata":{"id":"fd8dafc5"},"source":["## Pseudo Quantization\n","ì•„ë˜ ì½”ë“œëŠ” ì˜ì‚¬ ì–‘ìí™”(pseudo quantization)ì„ ìœ„í•œ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.\n","\n","Pseudo QuantizationëŠ” ëª¨ë¸ì˜ weightì™€ activationì„ ì‹¤ì œë¡œ ì–‘ìí™”í•˜ì§€ ì•Šê³ , ì–‘ìí™”ì˜ ì˜í–¥ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤. (ì¦‰, ê°€ì¥ ê°€ê¹Œìš´ ì–‘ìí™”ëœ ê°’ìœ¼ë¡œ ë°˜ì˜¬ë¦¼í•œ ë‹¤ìŒ, **ë‹¤ì‹œ ë¶€ë™ ì†Œìˆ˜ì ìœ¼ë¡œ ë³µì›(dequantizing)**í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.)\n","\n","ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” ì‹¤ì œ ì—°ì‚°ì—ì„œëŠ” FP16ì„ ì‚¬ìš©í•˜ì—¬ 8ë¹„íŠ¸ dynamic weight and activation qaunitzationì„ ì‹œë®¬ë ˆì´ì…˜ í•©ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":null,"id":"af56c647","metadata":{"id":"af56c647"},"outputs":[],"source":["import torch\n","from torch import nn\n","from functools import partial\n","\n","class W8A8Linear(nn.Module):\n","    def __init__(\n","        self,\n","        in_features,\n","        out_features,\n","        bias=True,\n","        act_quant=\"per_token\",\n","        quantize_output=False,\n","        quantize_bits=8\n","    ):\n","        super().__init__()\n","        self.in_features = in_features\n","        self.out_features = out_features\n","\n","        self.register_buffer(\n","            \"weight\",\n","            torch.randn(\n","                self.out_features,\n","                self.in_features,\n","                dtype=torch.float16,\n","                requires_grad=False,\n","            ),\n","        )\n","        if bias:\n","            self.register_buffer(\n","                \"bias\",\n","                torch.zeros(\n","                    (1, self.out_features), dtype=torch.float16, requires_grad=False\n","                ),\n","            )\n","        else:\n","            self.register_buffer(\"bias\", None)\n","\n","        if act_quant == \"per_token\":\n","            self.act_quant_name = \"per_token\"\n","            self.act_quant = partial(quantize_activation_per_token_absmax, n_bits=8)\n","        elif act_quant == \"per_tensor\":\n","            self.act_quant_name = \"per_tensor\"\n","            self.act_quant = partial(quantize_activation_per_tensor_absmax, n_bits=8)\n","        else:\n","            raise ValueError(f\"Invalid act_quant: {act_quant}\")\n","\n","        if quantize_output:\n","            self.output_quant_name = self.act_quant_name\n","            self.output_quant = self.act_quant\n","        else:\n","            self.output_quant_name = \"None\"\n","            self.output_quant = lambda x: x\n","\n","        self.quantize_bits = quantize_bits\n","\n","    def to(self, *args, **kwargs):\n","        super(W8A8Linear, self).to(*args, **kwargs)\n","        self.weight = self.weight.to(*args, **kwargs)\n","        if self.bias is not None:\n","            self.bias = self.bias.to(*args, **kwargs)\n","        return self\n","\n","    @torch.no_grad()\n","    def forward(self, x):\n","        q_x = self.act_quant(x)\n","        y = torch.functional.F.linear(q_x, self.weight, self.bias)\n","        q_y = self.output_quant(y)\n","        return q_y\n","\n","    @staticmethod\n","    def from_float(\n","        module, weight_quant=\"per_channel\", act_quant=\"per_token\", quantize_output=False, quantize_bits=8\n","    ):\n","        assert isinstance(module, torch.nn.Linear)\n","        new_module = W8A8Linear(\n","            module.in_features,\n","            module.out_features,\n","            module.bias is not None,\n","            act_quant=act_quant,\n","            quantize_output=quantize_output,\n","        )\n","        if weight_quant == \"per_channel\":\n","            new_module.weight = quantize_weight_per_channel_absmax(\n","                module.weight, n_bits=new_module.quantize_bits\n","            )  # use 8-bit integer for weight\n","        elif weight_quant == \"per_tensor\":\n","            new_module.weight = quantize_weight_per_tensor_absmax(\n","                module.weight, n_bits=new_module.quantize_bits\n","            )\n","        else:\n","            raise ValueError(f\"Invalid weight_quant: {weight_quant}\")\n","        new_module.weight_quant_name = weight_quant\n","        if module.bias is not None:\n","            new_module.bias = module.bias\n","        return new_module\n","\n","    def __repr__(self):\n","        return f\"W8A8Linear({self.in_features}, {self.out_features}, bias={self.bias is not None}, weight_quant={self.weight_quant_name}, act_quant={self.act_quant_name}, output_quant={self.output_quant_name})\"\n","\n","@torch.no_grad()\n","def quantize_weight_per_channel_absmax(w, n_bits=8):\n","    # w: (out_features, in_features)\n","    scales = w.abs().max(dim=-1, keepdim=True)[0]\n","    q_max = 2 ** (n_bits - 1) - 1\n","    scales.clamp_(min=1e-5).div_(q_max)\n","    w.div_(scales).round_().mul_(scales)\n","    return w\n","\n","\n","@torch.no_grad()\n","def quantize_weight_per_tensor_absmax(w, n_bits=8):\n","    # w: (out_features, in_features)\n","    scales = w.abs().max()\n","    q_max = 2 ** (n_bits - 1) - 1\n","    scales.clamp_(min=1e-5).div_(q_max)\n","    w.div_(scales).round_().mul_(scales)\n","    return w\n","\n","\n","@torch.no_grad()\n","def quantize_activation_per_token_absmax(t, n_bits=8):\n","    t_shape = t.shape\n","    t.view(-1, t_shape[-1])\n","    scales = t.abs().max(dim=-1, keepdim=True)[0]\n","    q_max = 2 ** (n_bits - 1) - 1\n","    scales.clamp_(min=1e-5).div_(q_max)\n","    t.div_(scales).round_().mul_(scales)\n","    return t\n","\n","\n","@torch.no_grad()\n","def quantize_activation_per_tensor_absmax(t, n_bits=8):\n","    t_shape = t.shape\n","    t.view(-1, t_shape[-1])\n","    scales = t.abs().max()\n","    q_max = 2 ** (n_bits - 1) - 1\n","    scales.clamp_(min=1e-5).div_(q_max)\n","    t.div_(scales).round_().mul_(scales)\n","    return t\n","\n","def quantize_opt(\n","    model, weight_quant=\"per_tensor\", act_quant=\"per_tensor\", quantize_bmm_input=True, quantize_bits=8\n","):\n","    from transformers.models.opt.modeling_opt import (\n","        OPTAttention,\n","        OPTDecoderLayer,\n","    )\n","\n","    for name, m in model.model.named_modules():\n","        if isinstance(m, OPTDecoderLayer):\n","            m.fc1 = W8A8Linear.from_float(\n","                m.fc1, weight_quant=weight_quant, act_quant=act_quant, quantize_bits=8\n","            )\n","            m.fc2 = W8A8Linear.from_float(\n","                m.fc2, weight_quant=weight_quant, act_quant=act_quant, quantize_bits=8\n","            )\n","        elif isinstance(m, OPTAttention):\n","            # Her we simulate quantizing BMM inputs by quantizing the output of q_proj, k_proj, v_proj\n","            m.q_proj = W8A8Linear.from_float(\n","                m.q_proj,\n","                weight_quant=weight_quant,\n","                act_quant=act_quant,\n","                quantize_output=quantize_bmm_input, quantize_bits=8\n","            )\n","            m.k_proj = W8A8Linear.from_float(\n","                m.k_proj,\n","                weight_quant=weight_quant,\n","                act_quant=act_quant,\n","                quantize_output=quantize_bmm_input, quantize_bits=8\n","            )\n","            m.v_proj = W8A8Linear.from_float(\n","                m.v_proj,\n","                weight_quant=weight_quant,\n","                act_quant=act_quant,\n","                quantize_output=quantize_bmm_input, quantize_bits=8\n","            )\n","            m.out_proj = W8A8Linear.from_float(\n","                m.out_proj, weight_quant=weight_quant, act_quant=act_quant, quantize_bits=8\n","            )\n","    return model"]},{"cell_type":"markdown","id":"a87c4b54","metadata":{"id":"a87c4b54"},"source":["ì´ì œ quantized 8-bit ëª¨ë¸ì˜ í˜¼ë€ë„(perplexity)ì™€ í¬ê¸°ë¥¼ í‰ê°€í•´ ë´…ì‹œë‹¤."]},{"cell_type":"code","execution_count":null,"id":"37ca07f9","metadata":{"id":"37ca07f9"},"outputs":[],"source":["llm_model.model_reset()\n","model_w8a8 = quantize_opt(llm_model.model, quantize_bits=8)\n","print(model_w8a8)\n","llm_model.model_change(model_w8a8)\n","\n","# Evaluate and delete the model\n","llm_model.model_evaluate(data_width=8, group_size=128)"]},{"cell_type":"markdown","id":"790d536c","metadata":{"id":"790d536c"},"source":["ëª¨ë¸ í¬ê¸°ê°€ ì¤„ì–´ë“  ê²ƒì€ í™•ì¸í•  ìˆ˜ ìˆì§€ë§Œ, í˜¼ë€ë„(perplexity)ëŠ” ì•½ê°„ ì¦ê°€í–ˆìŠµë‹ˆë‹¤."]},{"cell_type":"markdown","id":"bcc12e9b","metadata":{"id":"bcc12e9b"},"source":["AWQì˜ ê´€ì°°ì—ì„œì™€ ë§ˆì°¬ê°€ì§€ë¡œ, LLMì˜ í™œì„±í™”(activations)ì—ì„œ ì¼ë¶€ ì±„ë„ì— **ì•„ì›ƒë¼ì´ì–´(outliers)**ê°€ ì†ŒëŸ‰ ë°œìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤. íŠ¹ì • ì±„ë„ì— ì•„ì›ƒë¼ì´ì–´ê°€ ìˆëŠ” ê²½ìš°, ì´ëŠ” **ëª¨ë“  í† í°ì—ì„œ ì§€ì†ì ìœ¼ë¡œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.**\n","\n","ì£¼ì–´ì§„ í† í°ì— ëŒ€í•œ ì±„ë„ ê°„ì˜ ë¶„ì‚°(variance)ì€ í¬ì§€ë§Œ(ì¼ë¶€ ì±„ë„ì˜ í™œì„±í™”ëŠ” ë§¤ìš° í¬ê³ , ëŒ€ë¶€ë¶„ì€ ì‘ìŠµë‹ˆë‹¤), íŠ¹ì • ì±„ë„ì˜ í¬ê¸°(magnitude)ê°€ í† í° ê°„ì— ê°€ì§€ëŠ” ë¶„ì‚°ì€ ì‘ìŠµë‹ˆë‹¤(ì•„ì›ƒë¼ì´ì–´ ì±„ë„ì€ ì§€ì†ì ìœ¼ë¡œ í½ë‹ˆë‹¤).\n","\n","Smoothquant ë…¼ë¬¸ì˜ ê´€ì°°ì— ë”°ë¥´ë©´, ì´ëŸ¬í•œ í˜„ìƒì€ activationì—ì„œë§Œ ë°œê²¬ë˜ëŠ” í˜„ìƒì´ë©°, weightì—ì„œëŠ” ë°œê²¬ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n","\n","ê·¸ë ‡ê¸° ë–„ë¬¸ì—, AWQ ê¸°ë²•ê³¼ ê°™ì´ weightì— ëŒ€í•´ì„œëŠ” 4bit ì •ë„ì˜ ë‚®ì€ ì •ë°€ë„ë¡œ quantizationì´ ê°€ëŠ¥í•˜ì§€ë§Œ, activationì—ì„œëŠ” ë§¤ìš° í° ì •í™•ë„ í•˜ë½ì´ ë°œìƒí•©ë‹ˆë‹¤.\n"]},{"cell_type":"markdown","id":"c50a1ebc","metadata":{"id":"c50a1ebc"},"source":["## Migrate the quantization difficulty from activations to weights\n","\n","ì–‘ìí™” ì˜¤ë¥˜(quantization error)ë¥¼ ì¤„ì´ê¸° ìœ„í•´ì„œëŠ” ëª¨ë“  ì±„ë„ì— ëŒ€í•´ ìœ íš¨ ì–‘ìí™” ë¹„íŠ¸ìˆ˜ë¥¼ ì¦ê°€ì‹œì¼œì•¼ í•©ë‹ˆë‹¤.\n","\n","ê·¸ëŸ¬ë‚˜ ì—°ì‚° ê³¼ì •ì—ì„œ activationì€ ì±„ë„ ì°¨ì›ì´ ì•„ë‹Œ í† í° ì°¨ì›ì—ì„œ í–‰ë ¬ ê³±ì…ˆì´ ì´ë£¨ì–´ì§€ê¸° ë•Œë¬¸ì—, per-channel quantizationì„ ë„ì…í•˜ëŠ” ê²ƒìœ¼ë¡œëŠ” ì†ë„ì˜ í–¥ìƒì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n","\n","ëŒ€ì‹  Smoothquantì—ì„œëŠ” activationì„ per-channel smoothing fator $\\mathbf{s}$ë¡œ ë‚˜ëˆ„ì–´ \"smooth\"í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤.\n","\n","ì´ ë°©ë²•ì€ ê° activation ì±„ë„ì— ë…ë¦½ì ì¸ ìŠ¤ì¼€ì¼ë§ ì¸ìë¥¼ ì ìš©í•˜ì—¬ ì…ë ¥ í™œì„±í™”ì˜ ì´ìƒì¹˜(outliers)ë¥¼ í‰í™œí™”í•˜ê³ , ì´ë¡œ ì¸í•´ ì–‘ìí™” ê³¼ì •ì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì˜¤ë¥˜ì™€ ì •í™•ë„ ì†ì‹¤ì„ ìµœì†Œí™”í•©ë‹ˆë‹¤.\n","\n","ì¦‰, ê° í™œì„±í™” ì±„ë„ì˜ ìŠ¤ì¼€ì¼ì„ ì¡°ì •í•¨ìœ¼ë¡œì¨ ì „ì²´ í–‰ë ¬ì˜ ì–‘ìí™”ê°€ ë”ìš± íš¨ê³¼ì ì´ê³  ì•ˆì •ì ìœ¼ë¡œ ì´ë£¨ì–´ì§ˆ ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.\n","\n","$$\n","Y = (X \\text{diag}(s)^{-1}) \\cdot (\\text{diag}(s)W) = \\hat{X}\\hat{W}\n","$$\n","\n","\n","ì—¬ê¸°ì„œ ì…ë ¥ ğ‘‹ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì´ì „ì˜ ì„ í˜• ì—°ì‚°(ì˜ˆ: Linear layer, Layer Normalization ë“±)ì—ì„œ ìƒì„±ë˜ë¯€ë¡œ, ìš°ë¦¬ëŠ” ìŠ¤ì¼€ì¼ë§ íŒ©í„° $s$ë¥¼ ì´ì „ ë ˆì´ì–´ì˜ íŒŒë¼ë¯¸í„°ì— ì˜¤í”„ë¼ì¸ìœ¼ë¡œ ë¯¸ë¦¬ ê²°í•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ ì¶”ê°€ì ì¸ ìŠ¤ì¼€ì¼ë§ìœ¼ë¡œ ì¸í•œ ì»¤ë„ í˜¸ì¶œ ì˜¤ë²„í—¤ë“œê°€ ë°œìƒí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."]},{"cell_type":"markdown","id":"561dac5e","metadata":{"id":"561dac5e"},"source":["# [ì‹¤ìŠµ 3] Quantization difficulty migration\n","\n","ì‹¤ìŠµì„ í†µí•´ weightì—ëŠ” së¥¼ ê³±í•˜ê³ , activationì—ëŠ” së¥¼ ë‚˜ëˆ„ì–´ quantization ë‚œì´ë„ë¥¼ ë¶„ë°°í•´ ì¤€ ë‹¤ìŒ, quantizationì„ ì§„í–‰í•´ í˜¼ë€ë„(perplexity)ì˜ ë³€í™”ë¥¼ ê´€ì°°í•´ë³´ì„¸ìš”.\n","\n","ì¼ë°˜ì ì¸ Transformerì˜ ë ˆì´ì–´ êµ¬ì¡°ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n","\n","1. Self-Attention Block\n","\n","    Input â†’ LayerNorm â†’ Query/Key/Value ìƒì„± (FC) â†’ Attention ì—°ì‚° â†’ Softmax â†’ Attention Output\n","\n","2. Feed-Forward Network (FFN)\n","\n","    Attention Output â†’ LayerNorm â†’ FC1 â†’ í™œì„±í™” í•¨ìˆ˜ (ReLU, GELU ë“±) â†’ FC2 â†’ Output\n","\n","ê·¸ëŸ¬ë¯€ë¡œ Transformerì˜ ë ˆì´ì–´ì—ì„œ LayerNormì˜ ê°€ì¤‘ì¹˜ì— ìŠ¤ì¼€ì¼ë§ íŒ©í„° $s$ë¥¼ ë‚˜ëˆ„ê³ , FCì˜ ê°€ì¤‘ì¹˜ì— ìŠ¤ì¼€ì¼ë§ íŒ©í„° $s$ë¥¼ ê³±í•˜ë©´ weightì—ëŠ” së¥¼ ê³±í•˜ê³ , activationì—ëŠ” së¥¼ ë‚˜ëˆ„ëŠ” íš¨ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","\n","ì•„ë˜ ì½”ë“œë¥¼ ìˆ˜ì •í•˜ì—¬ LayerNormì˜ ê°€ì¤‘ì¹˜ì— ìŠ¤ì¼€ì¼ë§ íŒ©í„° $s$ë¥¼ ë‚˜ëˆ„ê³ , FCì˜ ê°€ì¤‘ì¹˜ì— ìŠ¤ì¼€ì¼ë§ íŒ©í„° $s$ë¥¼ ê³±í•´ì£¼ì„¸ìš”."]},{"cell_type":"code","execution_count":null,"id":"8d58d548","metadata":{"id":"8d58d548"},"outputs":[],"source":["@torch.no_grad()\n","def smooth_lm_by_scale(model, scale):\n","    for name, module in model.named_modules():\n","        if isinstance(module, OPTDecoderLayer):\n","            attn_ln = module.self_attn_layer_norm\n","            qkv = [\n","                module.self_attn.q_proj,\n","                module.self_attn.k_proj,\n","                module.self_attn.v_proj,\n","            ]\n","            smooth_ln_fcs_by_scale(attn_ln, qkv, scale)\n","\n","            ffn_ln = module.final_layer_norm\n","            fc1 = module.fc1\n","            smooth_ln_fcs_by_scale(ffn_ln, fc1, scale)\n","\n","@torch.no_grad()\n","def smooth_ln_fcs_by_scale(ln, fcs, scale):\n","    if not isinstance(fcs, list):\n","        fcs = [fcs]\n","    assert isinstance(ln, nn.LayerNorm)\n","    for fc in fcs:\n","        assert isinstance(fc, nn.Linear)\n","    ############### YOUR CODE STARTS HERE ###############\n","    # Step 1: layernormì˜ weightì™€ biasë¥¼ scaleë¡œ ë‚˜ëˆ„ì–´ì£¼ì„¸ìš”. (hint: div_()í•¨ìˆ˜ë¥¼ í†µí•´ tensor ì „ì²´ë¥¼ íŠ¹ì •í•œ ê°’ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.)\n","    ln.weight.div_(scale)\n","    ln.bias.div_(scale)\n","    ############### YOUR CODE ENDS HERE #################\n","\n","    for fc in fcs:\n","        ############### YOUR CODE STARTS HERE ###############\n","        # Step 2: fcì˜ weightì— scaleì„ ê³±í•´ì£¼ì„¸ìš”. (hint: mul_()í•¨ìˆ˜ë¥¼ í†µí•´ tensor ì „ì²´ì— íŠ¹ì •í•œ ê°’ì„ ê³±í•´ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.)\n","        fc.weight.mul_(scale)\n","        ############### YOUR CODE ENDS HERE #################\n"]},{"cell_type":"code","execution_count":null,"id":"edc223d5","metadata":{"id":"edc223d5"},"outputs":[],"source":["llm_model.model_reset()\n","smooth_lm_by_scale(llm_model.model, 5)\n","model_smoothquant_scale = quantize_opt(llm_model.model)\n","print(model_smoothquant_scale)\n","llm_model.model_change(model_smoothquant_scale)\n","\n","# Evaluate the model\n","llm_model.model_evaluate(data_width=8, group_size=128)"]},{"cell_type":"markdown","id":"4fef5e4c","metadata":{"id":"4fef5e4c"},"source":["ìŠ¤ì¼€ì¼ë§ì„ í†µí•´ì„œ ê°€ì¤‘ì¹˜ì™€ í™œì„±í™”ì˜ ì–‘ìí™” ë‚œì´ë„ë¥¼ ì ì ˆíˆ ë¶„ë°°í•˜ê³ , ê°€ì¤‘ì¹˜ì™€ í™œì„±í™”ë¥¼ ëª¨ë‘ 8bitë¡œ ìœ ì§€í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤."]},{"cell_type":"markdown","id":"1b015ccf","metadata":{"id":"1b015ccf"},"source":["ì´ë²ˆì—ëŠ” ì½”ë“œì—ì„œ ì„œë¡œ ë‹¤ë¥¸ ë‹¤ì–‘í•œ ìŠ¤ì¼€ì¼ë§ íŒ©í„° $s$(ì˜ˆ: 0.001, 0.01, 1)ì„ ì‹œë„í•˜ê³  í˜¼ë€ë„(perplexity)ì˜ ë³€í™”ë¥¼ ê´€ì°°í•´ë³´ê² ìŠµë‹ˆë‹¤."]},{"cell_type":"code","execution_count":null,"id":"2131db92","metadata":{"id":"2131db92"},"outputs":[],"source":["for scale_factor in [0.001,0.01,0.1]:\n","    llm_model.model_reset()\n","    smooth_lm_by_scale(llm_model.model,scale_factor)\n","    model = quantize_opt(llm_model.model)\n","    llm_model.model_change(model)\n","\n","    # Evaluate the model\n","    print(f\"scale_factor={scale_factor}\")\n","    llm_model.model_evaluate(data_width=8, group_size=128)"]},{"cell_type":"markdown","id":"10278aff","metadata":{"id":"10278aff"},"source":["## [ì‹¤ìŠµ 4] Scale factor sampling\n","\n","ìŠ¤ì¼€ì¼ë§ íŒ©í„° $s$ê°’ì˜ ì„¤ì •ì— ë”°ë¼ í˜¼ë€ë„(perplexity)ê°€ ë¨¼ì € ë³€í™”í•˜ëŠ” ê²ƒì„ ê´€ì°°í–ˆë‚˜ìš”?\n","\n","\n","ìš°ë¦¬ì˜ ëª©í‘œëŠ” ê° ì±„ë„ë³„ ìŠ¤ì¼€ì¼ë§ íŒ©í„° së¥¼ ì„ íƒí•˜ì—¬  XÌ‚ = Xdiag(s)â»Â¹ê°€ ì–‘ìí™”í•˜ê¸° ì‰½ë„ë¡ ë§Œë“œëŠ” ê²ƒì…ë‹ˆë‹¤.\n","\n","ì–‘ìí™” ì˜¤ë¥˜ë¥¼ ì¤„ì´ê¸° ìœ„í•´ ëª¨ë“  ì±„ë„ì˜ ìœ íš¨ ì–‘ìí™” ë¹„íŠ¸ë¥¼ ëŠ˜ë ¤ì•¼ í•©ë‹ˆë‹¤.\n","\n","ê°€ì¥ ê°„ë‹¨í•œ ì„ íƒì€ ì±„ë„ë³„ë¡œ ì„œë¡œ ë‹¤ë¥¸ ìŠ¤ì¼€ì¼ë§ íŒ©í„°ë¥¼ ì„¤ì •í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n","\n","ìŠ¤ì¼€ì¼ë§ íŒ©í„°ë¥¼ weightì˜ ìµœëŒ€ê°’ìœ¼ë¡œ ì„¤ì •í•˜ë©´ weightì˜ ì–‘ìí™” ë‚œì´ë„ê°€ ì‰¬ì›Œì§‘ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ activationì˜ ì–‘ìí™”ëŠ” ì–´ë ¤ì›Œì§‘ë‹ˆë‹¤.\n","\n","ë°˜ëŒ€ë¡œ, ìŠ¤ì¼€ì¼ë§ íŒ©í„°ë¥¼ activationì˜ ìµœëŒ€ê°’ìœ¼ë¡œ ì„¤ì •í•˜ë©´ weightì˜ ì–‘ìí™”ê°€ ì–´ë ¤ì›Œì§‘ë‹ˆë‹¤.\n","\n","ìš°ë¦¬ëŠ” weightì™€ activationì˜ ì–‘ìí™” ë‚œì´ë„ ì‚¬ì´ì—ì„œ ê· í˜•ì„ ë§ì¶”ê¸° ìœ„í•´ ìŠ¤ì¼€ì¼ë§ íŒ©í„° së¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì„¤ì •í•©ë‹ˆë‹¤.\n","\n","$s = \\max(|X|)^{\\alpha} / \\max(|W|)^{1-\\alpha}$\n","\n","ì•„ë˜ ì½”ë“œë¥¼ ìˆ˜ì •í•˜ì—¬ ìŠ¤ì¼€ì¼ë§ íŒ©í„° së¥¼ ìœ„ì˜ ì‹ê³¼ ê°™ì´ ì„¤ì •í•´ì£¼ì„¸ìš”."]},{"cell_type":"code","execution_count":null,"id":"AQtTutXMuIYD","metadata":{"id":"AQtTutXMuIYD"},"outputs":[],"source":["@torch.no_grad()\n","def smooth_ln_fcs(ln, fcs, act_scales, alpha=0.5):\n","    if not isinstance(fcs, list):\n","        fcs = [fcs]\n","    assert isinstance(ln, nn.LayerNorm)\n","    for fc in fcs:\n","        assert isinstance(fc, nn.Linear)\n","        assert ln.weight.numel() == fc.in_features == act_scales.numel()\n","\n","    device, dtype = fcs[0].weight.device, fcs[0].weight.dtype\n","    act_scales = act_scales.to(device=device, dtype=dtype)\n","    weight_scales = torch.cat(\n","        [fc.weight.abs().max(dim=0, keepdim=True)[0] for fc in fcs], dim=0\n","    )\n","    weight_scales = weight_scales.max(dim=0)[0].clamp(min=1e-5)\n","\n","    scales = (\n","        ############### YOUR CODE STARTS HERE ###############\n","        #Activation Scales ê°’ê³¼ Weight Scales ê°’ì— alphaë¥¼ ì ì ˆíˆ ê±°ë“­ì œê³±í•´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤.\n","        #Hint: pow()í•¨ìˆ˜ë¥¼ í†µí•´ì„œ ê±°ë“­ì œê³±ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","        act_scales.pow(alpha) / weight_scales.pow(1 - alpha)\n","        ############### YOUR CODE ENDS HERE #################\n","    )\n","\n","    scales.clamp(min=1e-5).to(device).to(dtype)\n","\n","    ln.weight.div_(scales)\n","    ln.bias.div_(scales)\n","\n","    for fc in fcs:\n","        fc.weight.mul_(scales.view(1, -1))\n"]},{"cell_type":"markdown","id":"sZKrDAfywHK4","metadata":{"id":"sZKrDAfywHK4"},"source":["ì—¬ê¸°ì„œ í™œì„±í™” ë²”ìœ„ëŠ” ë™ì ì´ë©° ì…ë ¥ ìƒ˜í”Œì— ë”°ë¼ ë‹¬ë¼ì§‘ë‹ˆë‹¤.\n","\n","ì‚¬ì „ í›ˆë ¨ ë°ì´í„° ì„¸íŠ¸ì˜ ë³´ì • ìƒ˜í”Œì„ ì‚¬ìš©í•˜ì—¬ í™œì„±í™” ì±„ë„ì˜ í¬ê¸°ë¥¼ ì¶”ì •í•´ë³´ê² ìŠµë‹ˆë‹¤.\n","\n","ì•„ë˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë©´ 512ê°œì˜ ì‚¬ì „ í›ˆë ¨ ìƒ˜í”Œ ë°ì´í„° ì„¸íŠ¸ë¥¼ í†µí•´ ìë™ìœ¼ë¡œ ì ì ˆí•œ ìŠ¤ì¼€ì¼ë§ íŒ©í„° $s$ê°’ì„ ì°¾ì•„ ì–‘ìí™”ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":null,"id":"178b1225","metadata":{"id":"178b1225"},"outputs":[],"source":["import functools\n","def get_act_scales(model, tokenizer, dataset_path, num_samples=512, seq_len=512):\n","    model.eval()\n","    device = next(model.parameters()).device\n","    act_scales = {}\n","\n","    def stat_tensor(name, tensor):\n","        hidden_dim = tensor.shape[-1]\n","        tensor = tensor.view(-1, hidden_dim).abs().detach()\n","        comming_max = torch.max(tensor, dim=0)[0].float().cpu()\n","        if name in act_scales:\n","            act_scales[name] = torch.max(act_scales[name], comming_max)\n","        else:\n","            act_scales[name] = comming_max\n","\n","    def stat_input_hook(m, x, y, name):\n","        if isinstance(x, tuple):\n","            x = x[0]\n","        stat_tensor(name, x)\n","\n","    hooks = []\n","    for name, m in model.named_modules():\n","        if isinstance(m, nn.Linear):\n","            hooks.append(\n","                m.register_forward_hook(functools.partial(stat_input_hook, name=name))\n","            )\n","\n","    dataset = load_dataset(\"json\", data_files=dataset_path, split=\"train\")\n","    dataset = dataset.shuffle(seed=42)\n","\n","    for i in tqdm(range(num_samples)):\n","        input_ids = tokenizer(\n","            dataset[i][\"text\"], return_tensors=\"pt\", max_length=seq_len, truncation=True\n","        ).input_ids.to(device)\n","        model(input_ids)\n","\n","    for h in hooks:\n","        h.remove()\n","\n","    return act_scales"]},{"cell_type":"code","execution_count":null,"id":"c1dee862","metadata":{"id":"c1dee862"},"outputs":[],"source":["@torch.no_grad()\n","def smooth_lm(model, scales, alpha=0.5):\n","    for name, module in model.named_modules():\n","        if isinstance(module, OPTDecoderLayer):\n","            attn_ln = module.self_attn_layer_norm\n","            qkv = [\n","                module.self_attn.q_proj,\n","                module.self_attn.k_proj,\n","                module.self_attn.v_proj,\n","            ]\n","            qkv_input_scales = scales[name + \".self_attn.q_proj\"]\n","            smooth_ln_fcs(attn_ln, qkv, qkv_input_scales, alpha)\n","\n","            ffn_ln = module.final_layer_norm\n","            fc1 = module.fc1\n","            fc1_input_scales = scales[name + \".fc1\"]\n","            smooth_ln_fcs(ffn_ln, fc1, fc1_input_scales, alpha)"]},{"cell_type":"code","execution_count":null,"id":"deaf4309","metadata":{"id":"deaf4309"},"outputs":[],"source":["llm_model.model_reset()\n","\n","act_scales = get_act_scales(\n","        llm_model.model, llm_model.tokenizer, datapath, 512, 512)\n","smooth_lm(llm_model.model, act_scales)\n","model_sampled = quantize_opt(llm_model.model)\n","llm_model.model_change(model_sampled)\n","\n","# Evaluate the model\n","llm_model.model_evaluate(data_width=8, group_size=128)\n","\n","del llm_model\n","torch.cuda.empty_cache()"]},{"cell_type":"markdown","source":["# Rotation Based Quantization\n","ìµœê·¼ì—ëŠ” LLM Quantizationì˜ Outlier ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ Rotation Matrixë¥¼ ê³±í•´ì„œ Outlierë¥¼ ì œê±°í•˜ëŠ” ë°©ë²•ë“¤ì´ ì œì‹œë˜ê³  ìˆìŠµë‹ˆë‹¤. (QuaRot, SpinQuant ë“±)\n","\n","![SpinQuant](https://raw.githubusercontent.com/facebookresearch/SpinQuant/refs/heads/main/SpinQuant.png)\n","\n","í•´ë‹¹ ê¸°ë²•ë“¤ì€ ì§êµ í–‰ë ¬ì˜ ì•„ë˜ì™€ ê°™ì€ íŠ¹ì„±ì„ í™œìš©í•©ë‹ˆë‹¤.\n","\n","1. $$ R\\,R^{T} = I $$\n","\n","2. ë²¡í„° Vì— ì§êµ í–‰ë ¬ Rì„ ê³±í•˜ë©´, ê¸¸ì´ëŠ” ê°™ìœ¼ë‚˜ ë°©í–¥ì´ ë°”ë€ ë²¡í„° V'ë¥¼ êµ¬í•  ìˆ˜ ìˆìŒ\n","\n","\n","\n","## ìˆ˜ì‹ ìœ ë„\n","\n","1. ì›ë˜ ì—°ì‚°  \n","   $$\n","     y = x\\,W\n","   $$\n","\n","2. ì§êµ í–‰ë ¬ $R$ ë„ì…  \n","   $$\n","     y = x\\,I\\,W = x\\,(RR^{T})\\,W = (x\\,R)\\,(R^{T}\\,W)\n","   $$\n","\n","3. ìƒˆë¡œìš´ ë³€ìˆ˜ë¡œ ì •ì˜\n","   $$\n","     x' = x\\,R^{T}\n","     \\quad\n","     W' = R\\,W\n","   $$\n","   ì´ë•Œ  \n","   $$\n","     y = x'\\,W'\n","     = x\\,W\n","   $$  \n","   ê°€ ìˆ˜ì‹ì ìœ¼ë¡œ ë³´ì¡´ë¨\n","  \n","## ì¥ì \n","  - íšŒì „ì„ í†µí•´ ë¶„í¬ë¥¼ ë¶„ì‚°ì‹œì¼œ Outlier í˜„ìƒì„ ì™„í™”  \n","  - ì‚¬ì „ì— Weightì— ê³±í•´ë‘ëŠ” ê²ƒì„ í†µí•´ ì ìš© ê°€ëŠ¥ ë° ì˜¨ë¼ì¸ ì—°ì‚° ì œê±° ê°€ëŠ¥"],"metadata":{"id":"eDeUfFGQyRNv"},"id":"eDeUfFGQyRNv"},{"cell_type":"code","source":["llm_model = LLMModel(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")"],"metadata":{"id":"jIHqRFFQIl8l"},"id":"jIHqRFFQIl8l","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_orthogonal_matrix(size, mode=\"random\", dtype=torch.float32, device=\"cpu\"):\n","    if mode == \"random\":\n","        A = torch.randn(size, size, dtype=torch.float32, device=device)\n","        Q, R = torch.linalg.qr(A)\n","        Q *= torch.sign(torch.diag(R)).unsqueeze(0)\n","        return Q.to(dtype)\n","    else:\n","        raise ValueError(f\"Unknown mode: {mode}\")\n","\n","dummy_vector = torch.randn(100)\n","dummy_vector[50] = 30\n","\n","rotation_matrix = get_orthogonal_matrix(100)\n","rotated_vector = rotation_matrix @ dummy_vector\n","\n","def plot_vector(vec, title):\n","    plt.figure(figsize=(5, 2))\n","    plt.plot(vec.abs().numpy(), linewidth=2)\n","    plt.title(title, fontsize=14)\n","    plt.xlabel('Index', fontsize=12)\n","    plt.ylabel('Absolute Value', fontsize=12)\n","    plt.grid(True, linestyle='--', alpha=0.6)\n","    plt.tight_layout()\n","    plt.show()\n","\n","print(rotation_matrix)\n","print(torch.round(rotation_matrix @ rotation_matrix.T))\n","plot_vector(dummy_vector, 'Original Vector (Absolute Values)')\n","plot_vector(rotated_vector, 'Rotated Vector (Absolute Values)')"],"metadata":{"id":"RB8t1atrqqaT"},"id":"RB8t1atrqqaT","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def quantize_tinyllama(\n","    model, weight_quant=\"per_tensor\", act_quant=\"per_tensor\", quantize_bmm_input=True, quantize_bits=4\n","):\n","    \"\"\"\n","    Quantize TinyLlama model using W8A8Linear layers.\n","    \"\"\"\n","    for name, m in model.model.named_modules():\n","        if isinstance(m, torch.nn.Linear):\n","            # Skip lm_head as it's handled separately\n","            if \"lm_head\" in name:\n","                continue\n","\n","            # Create quantized linear layer\n","            quantized_layer = W8A8Linear.from_float(\n","                m, weight_quant=weight_quant, act_quant=act_quant, quantize_bits=4\n","            )\n","\n","            # Replace the original layer with quantized one\n","            # We need to find the parent module and replace the child\n","            parent_name = \".\".join(name.split(\".\")[:-1])\n","            child_name = name.split(\".\")[-1]\n","\n","            if parent_name:\n","                parent = model.model.get_submodule(parent_name)\n","                setattr(parent, child_name, quantized_layer)\n","            else:\n","                # Root level module\n","                setattr(model.model, child_name, quantized_layer)\n","\n","    return model"],"metadata":{"id":"9oSOzVPXd5lo"},"id":"9oSOzVPXd5lo","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Layernorm â†” Linear Fusion\n","\n","ì‹¤ì œ ëª¨ë¸ì—ì„œëŠ” Rotation Matrix ì‚¬ì´ì— Layernormì´ ì¡´ì¬í•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.\n","\n","![LayerNorm](https://miro.medium.com/v2/resize:fit:1252/1*kC-cWBWDEZpkSCtYIUsj4w.png)\n","\n","Normalization Layerì˜ ì˜í–¥ìœ¼ë¡œ Rotation Matrixê°€ ê³±í•´ì§€ì§€ ëª»í•´ ì •ìƒì ìœ¼ë¡œ ì œê±°ë˜ì§€ ëª»í•˜ê³  ëª¨ë¸ì˜ ì—°ì‚°ì´ ë¶€ì •í™•í•´ì§€ëŠ” ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","\n","ë”°ë¼ì„œ, Rotation ì ìš© ì´ì „ì— Normalization Layerë¥¼ Linear Layerì™€ Fusioní•´ì•¼ í•©ë‹ˆë‹¤."],"metadata":{"id":"TrHadElhixtg"},"id":"TrHadElhixtg"},{"cell_type":"code","source":["# Layer Norm Fusion Functions for TinyLlama\n","def fuse_ln_linear(layernorm, linear_layers):\n","    \"\"\"\n","    Fuse the linear operations in Layernorm into the adjacent linear blocks.\n","    \"\"\"\n","    for linear in linear_layers:\n","        linear_dtype = linear.weight.dtype\n","\n","        # Calculating new weight and bias\n","        W_ = linear.weight.data.double()\n","        linear.weight.data = (W_ * layernorm.weight.double()).to(linear_dtype)\n","\n","        if hasattr(layernorm, \"bias\") and layernorm.bias is not None:\n","            if linear.bias is None:\n","                linear.bias = torch.nn.Parameter(\n","                    torch.zeros(linear.out_features, dtype=torch.float64)\n","                )\n","            linear.bias.data = linear.bias.data.double() + torch.matmul(\n","                W_, layernorm.bias.double()\n","            )\n","            linear.bias.data = linear.bias.data.to(linear_dtype)\n","\n","def fuse_layer_norms_tinyllama(model):\n","    \"\"\"\n","    Fuse layer norms for TinyLlama model structure.\n","    \"\"\"\n","    # Embedding fusion\n","    for W in [model.model.embed_tokens]:\n","        W_ = W.weight.data.double()\n","        W.weight.data = (W_ - W_.mean(dim=-1, keepdim=True)).to(W.weight.data.dtype)\n","\n","    layers = [layer for layer in model.model.layers]\n","\n","    # Fuse the linear operations in Layernorm into the adjacent linear blocks.\n","    for layer in layers:\n","        # fuse the input layernorms into the linear layers\n","        fuse_ln_linear(\n","            layer.input_layernorm,\n","            [layer.self_attn.q_proj, layer.self_attn.k_proj, layer.self_attn.v_proj]\n","        )\n","        fuse_ln_linear(\n","            layer.post_attention_layernorm,\n","            [layer.mlp.gate_proj, layer.mlp.up_proj]\n","        )\n","\n","        # Set layernorm weights to ones\n","        W_norm = layer.input_layernorm.weight.data\n","        layer.input_layernorm.weight.data = torch.ones_like(W_norm)\n","        W_norm = layer.post_attention_layernorm.weight.data\n","        layer.post_attention_layernorm.weight.data = torch.ones_like(W_norm)\n","\n","    # Fuse final norm into lm_head\n","    fuse_ln_linear(\n","        model.model.norm,\n","        [model.lm_head],\n","    )\n","    W_norm = model.model.norm.weight.data\n","    model.model.norm.weight.data = torch.ones_like(W_norm)"],"metadata":{"id":"jFe23ot0ePl4"},"id":"jFe23ot0ePl4","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## [ì‹¤ìŠµ 5] Rotate Matrix ì ìš©\n","\n","QuaRotëŠ” R1ë§Œ ì‚¬ìš©í•˜ì—¬ Roationì„ ì ìš©í•©ë‹ˆë‹¤.\n","\n","ê·¸ë¥¼ ë³´ì™„í•œ SpinQuantì—ì„œëŠ” R2, R3, R4 ë“± ë‹¤ì–‘í•œ Rotation Matrixë¥¼ ì ìš©í•˜ì—¬ Quantization ì •í™•ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.\n","\n","ê·¸ëŸ¬ë‚˜, R2ëŠ” R1ê³¼ ìœ ì‚¬í•˜ê²Œ ì ìš© ê°€ëŠ¥í•˜ê³ , R3ì™€ R4ëŠ” On-lineì—ì„œ êµ¬í•´ì§€ëŠ” Matrixì´ê¸° ë•Œë¬¸ì— êµ¬í˜„ ë‚œì´ë„ë¥¼ ë‚®ì¶”ê¸° ìœ„í•´ QuaRotì„ êµ¬í˜„í•˜ëŠ” ê²ƒìœ¼ë¡œ í•˜ê² ìŠµë‹ˆë‹¤.\n","\n","QuaRot í˜¹ì€ SpinQuant ê·¸ë¦¼ì„ ì°¸ê³ í•˜ì…”ì„œ ê°ê°ì˜ ì—°ì‚°ì— R1ì´ ì–´ë–»ê²Œ ì ìš©ë  ê²ƒì¸ì§€ êµ¬í˜„í•´ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤."],"metadata":{"id":"hvTcVLnimz2D"},"id":"hvTcVLnimz2D"},{"cell_type":"code","source":["def rotate_model_weight(\n","    model, R1\n","):\n","    from transformers.models.opt.modeling_opt import OPTLearnedPositionalEmbedding\n","    for n, m in model.named_modules():\n","      ############### YOUR CODE STARTS HERE ###############\n","      # Pytorchì—ì„œ @ ì—°ì‚°ì´ Dot Product ì„ì„ ì‚¬ìš©í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n","      # nn.Linear ì—°ì‚°ì˜ ParameterëŠ” W^T í˜•íƒœë¡œ ì €ì¥ë˜ì–´ ìˆë‹¤ëŠ” ê²ƒì„ ìœ ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n","      # Embedding Parameter Shape : (Num_Tokens, Hidden_dim)\n","      # Linear Parameter Shape : (Output_Channel, Input_Channel)\n","      # Roation Matrix Shape : (Hidden_dim, Hidden_dim)\n","\n","      if isinstance(m, nn.Embedding):\n","        W_ = m.weight.data\n","        m.weight.data = W_ @ R1\n","\n","      if isinstance(m, nn.Linear):\n","        if \"o_proj\" in n or \"down_proj\" in n:\n","          # Att Out Proj, FFN Down Proj\n","          W_ = m.weight.data\n","          m.weight.data = R1.T @ W_\n","\n","        else:\n","          # QKV Proj, FFN Up Proj, FFN Gate Proj\n","          W_ = m.weight.data\n","          m.weight.data = W_ @ R1\n","\n","      ############### YOUR CODE ENDS HERE #################\n","\n","      torch.cuda.empty_cache()"],"metadata":{"id":"huCR1D1d3kf6"},"id":"huCR1D1d3kf6","execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"\\nOriginal ëª¨ë¸ ì„±ëŠ¥ ì¸¡ì • ì¤‘...\")\n","llm_model.model_reset()\n","original_perplexity = llm_model.model_evaluate(data_width=16, group_size=128)\n","output_orig = llm_model.model(llm_model.testenc[:,:500].to(llm_model.model.device), output_hidden_states=True)\n","torch.cuda.empty_cache()"],"metadata":{"id":"JiIhAnRdda4P"},"id":"JiIhAnRdda4P","execution_count":null,"outputs":[]},{"cell_type":"code","source":["Q_BITS = 8\n","\n","print(\"\\nQuantizationë§Œ ì ìš©í•œ ëª¨ë¸ ì„±ëŠ¥ ì¸¡ì • ì¤‘...\")\n","llm_model.model_reset()\n","model = quantize_tinyllama(llm_model.model, quantize_bits=Q_BITS)\n","llm_model.model_change(model)\n","quantized_only_perplexity = llm_model.model_evaluate(data_width=Q_BITS, group_size=128)\n","torch.cuda.empty_cache()"],"metadata":{"id":"wnicpydXIsYl"},"id":"wnicpydXIsYl","execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"\\nRotation + Quantization ì ìš©í•œ ëª¨ë¸ ì„±ëŠ¥ ì¸¡ì • ì¤‘...\")\n","llm_model.model_reset()\n","fuse_layer_norms_tinyllama(llm_model.model)\n","hidden_size = llm_model.model.config.hidden_size\n","R1_random = get_orthogonal_matrix(hidden_size, mode=\"random\", dtype=llm_model.model.dtype, device=llm_model.model.device)\n","rotate_model_weight(llm_model.model, R1_random)\n","model = quantize_tinyllama(llm_model.model, quantize_bits=Q_BITS)\n","llm_model.model_change(model)\n","rotation_quantized_perplexity = llm_model.model_evaluate(data_width=Q_BITS, group_size=128)\n","output_rotated = llm_model.model(llm_model.testenc[:,:500].to(llm_model.model.device), output_hidden_states=True)\n","torch.cuda.empty_cache()"],"metadata":{"id":"qAu-eHGJItBg"},"id":"qAu-eHGJItBg","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def plot_2d(data, title):\n","    # Get dimensions of hidden states - handle different shapes\n","    if len(data.shape) == 3:  # (batch, seq_len, hidden_dim)\n","        data = data[0]  # Take first batch\n","    elif len(data.shape) == 2:  # (seq_len, hidden_dim)\n","        pass\n","    else:\n","        print(f\"Unexpected data shape: {data.shape}\")\n","        return\n","\n","    seq_len, hidden_dim = data.shape\n","\n","    mean_activations = np.mean(np.abs(data), axis=0)\n","\n","    # 2D Plot\n","    plt.figure(figsize=(12, 6))\n","    plt.plot(np.arange(hidden_dim), mean_activations, color='blue', linewidth=1.5)\n","\n","    plt.xlabel(\"Hidden Dimension\", fontsize=12)\n","    plt.ylabel(\"Absolute Value\", fontsize=12)\n","    plt.title(f\"Hidden States Mean Activation - {title}\", fontsize=14)\n","\n","    plt.grid(True, linestyle=\"--\", alpha=0.6)\n","    plt.tight_layout()\n","    plt.show()\n","\n","# ì‚¬ìš© ì˜ˆì‹œ\n","plot_2d(output_orig.hidden_states[16][:, 100:].detach().cpu().numpy(), \"Original\")\n","plot_2d(output_rotated.hidden_states[16][:, 100:].detach().cpu().numpy(), \"Rotated\")\n"],"metadata":{"id":"rSiV8ayaew7s"},"id":"rSiV8ayaew7s","execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.19"}},"nbformat":4,"nbformat_minor":5}