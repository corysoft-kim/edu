{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "89c8a5ae-3dcf-4dec-9246-e4de57e21b53",
      "metadata": {
        "id": "89c8a5ae-3dcf-4dec-9246-e4de57e21b53"
      },
      "source": [
        "# **AI Application Specialist Practical Problem 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## assets.zip 파일을 업로드 하세요"
      ],
      "metadata": {
        "id": "1EFQPmeRy020"
      },
      "id": "1EFQPmeRy020"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "IB_iGPhsyz69",
        "collapsed": true
      },
      "id": "IB_iGPhsyz69",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 업로드한 파일의 압축을 푸세요"
      ],
      "metadata": {
        "id": "XPeowTsky7QX"
      },
      "id": "XPeowTsky7QX"
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip ./assets.zip"
      ],
      "metadata": {
        "id": "hNCtlUWOy7vU"
      },
      "id": "hNCtlUWOy7vU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 시험을 위한 라이브러리를 설치하세요. 설치 중간에 나오는 error는 무시해 주세요~. colab환경과 라이브러리 충돌에 관한 에러로 시험의 결과에 영향을 주지 않습니다."
      ],
      "metadata": {
        "id": "i0EXlUY6zEuH"
      },
      "id": "i0EXlUY6zEuH"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets\n",
        "!pip install -q openai"
      ],
      "metadata": {
        "id": "sRRu1gxtzDgB"
      },
      "id": "sRRu1gxtzDgB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper 함수들을 실행해 주세요"
      ],
      "metadata": {
        "id": "38yl61dtzy0G"
      },
      "id": "38yl61dtzy0G"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbc49257-e510-463d-8bef-93589902b6a3",
      "metadata": {
        "id": "cbc49257-e510-463d-8bef-93589902b6a3",
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "### helper functions\n",
        "def get_queries():\n",
        "    queries = [\n",
        "        \"삼성 갤럭시s24를 매력적인 한문장으로 홍보해주세요.\",\n",
        "        \"삼성 갤럭시 버즈3를 십대들이 좋아하는 한문장으로 홍보해주세요.\",\n",
        "        \"삼성 갤럭시 링 홍보문구를 스펙 고려해서 한문장으로 만들어 주세요.\",\n",
        "        \"삼성 전자렌지를 매력적인 한문장으로 홍보해주세요.\",\n",
        "        \"삼성 냉장고를 한 문장으로 홍보한다면?\",\n",
        "    ]\n",
        "\n",
        "    return queries\n",
        "\n",
        "def get_prompt(context, query):\n",
        "    prompt_msg = f\"<|USER|>Context information is below.\\n---------------------\\n{context}\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: {query}\\nAnswer: <|ASSISTANT|>\"\n",
        "    return prompt_msg\n",
        "\n",
        "def pretty_print(title, msg):\n",
        "    print(\"#\" * 10,\" \", title,\" \", \"#\" * 10)\n",
        "    print(msg)\n",
        "    print(\"#\" * 34)\n",
        "    print(\"\\n\")\n",
        "\n",
        "def get_specs_docs(spec_docs_dir =\"\"):\n",
        "    from pathlib import Path\n",
        "    from glob import glob\n",
        "    spec_paths = glob(str(Path(spec_docs_dir)) + \"/*.txt\")\n",
        "    spec_raw_text_li = []\n",
        "    for spec_path in spec_paths:\n",
        "        with open(Path(spec_path), encoding=\"utf-8\") as f:\n",
        "            content = f.read()\n",
        "            spec_raw_text_li.append(content)\n",
        "    return spec_raw_text_li\n",
        "\n",
        "def display_plt_img(img_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "    from matplotlib.gridspec import GridSpec\n",
        "    from PIL import Image\n",
        "    plt.figure(figsize = (20,16))\n",
        "    plt.imshow(Image.open(img_path))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "690b07bf-486a-4c40-9046-48323cf97fc6",
      "metadata": {
        "id": "690b07bf-486a-4c40-9046-48323cf97fc6"
      },
      "source": [
        "# Step 1. Retreiver"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "273adbbd-e063-492d-8f18-721e584513e6",
      "metadata": {
        "id": "273adbbd-e063-492d-8f18-721e584513e6"
      },
      "source": [
        "5개 제품의 Spec문서는 ./data/spec_docs/ 에 txt파일 형태로 제공, 사용자의 각 제품에 대한 질문은 get_queries()로 확인 가능함.\n",
        "각각 질문에 대응해서 적합한 spec_docs 폴더 안의 spec documents를 찾아내는 Retriever Class를 완성하세요"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17c0ca01-3c03-4bcd-98e5-c2dfedcab579",
      "metadata": {
        "id": "17c0ca01-3c03-4bcd-98e5-c2dfedcab579"
      },
      "outputs": [],
      "source": [
        "##### model 및 spec docs 불러오기 ####\n",
        "embedding_model_name = \"BAAI/bge-m3\"\n",
        "SPEC_DOCS_DIR = \"./data/spec_docs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2470d2a-7b03-4fd2-996e-305c67a4436b",
      "metadata": {
        "id": "d2470d2a-7b03-4fd2-996e-305c67a4436b",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "spec_docs = get_specs_docs(spec_docs_dir=SPEC_DOCS_DIR)\n",
        "for i, spec_doc in enumerate(spec_docs):\n",
        "    print(i,spec_doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0aed1980-af68-42e8-b3f2-6130c5d5bf89",
      "metadata": {
        "id": "0aed1980-af68-42e8-b3f2-6130c5d5bf89"
      },
      "outputs": [],
      "source": [
        "queries = get_queries()\n",
        "print(queries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9381294a-df56-4964-b23f-24dbb52640a5",
      "metadata": {
        "id": "9381294a-df56-4964-b23f-24dbb52640a5"
      },
      "outputs": [],
      "source": [
        "### Retriever를 위한 라이브러리 불러오기\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26f3b920-2ac0-4de3-bfc3-2f4aebf034d1",
      "metadata": {
        "id": "26f3b920-2ac0-4de3-bfc3-2f4aebf034d1"
      },
      "source": [
        "Q A-1) get_embedding(text)구현 (text->embedding 구현)\n",
        " - 함수 인자로 받은 text를 self.model을 이용, embedding vector로 변환 후 반환\n",
        "   1. self.tokenizer를 사용하여 tokenization 후, self.model에 입력하여 embedding matrix (#tokens * embedding_size) 생성\n",
        "   2. embedding matrix를 torch.mean을 사용하여 embedding_size의 embedding vector 반환\n",
        "\n",
        "Q A-2) build_doc_embedding()구현 (spec문서들->embedding 구현)\n",
        " - 각 document에 대한 embedding을 생성\n",
        "   1. 각 document를 get_embedding()을 사용하여 tensor 타입의 matrix (len(self.documents) * self.model.config.hidden_size) 반환\n",
        "\n",
        "Q A-3) retrieve_doc(query)구현 (text->top-1 doc)\n",
        "- 함수 인자로 받은 query를 documents_embeddings와 유사도 비교, query와 가장 유사한 document 1개를 반환.\n",
        "- 유사도 비교는 Retriever class에 구현된 cosine_similarity() 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dc81ba4-82c0-4d06-93ea-781487d5c6d5",
      "metadata": {
        "id": "8dc81ba4-82c0-4d06-93ea-781487d5c6d5"
      },
      "outputs": [],
      "source": [
        "class Retriever:\n",
        "    def __init__(self, documents, embedding_model_name):\n",
        "        self.documents = documents\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(embedding_model_name)\n",
        "        self.model = AutoModel.from_pretrained(embedding_model_name)\n",
        "        self.documents_embeddings = self.build_docs_embedding()\n",
        "\n",
        "    def get_embedding(self, text):\n",
        "        ### Q A-1) 작성 필요\n",
        "        return embedding\n",
        "\n",
        "    def build_docs_embedding(self):\n",
        "        ### Q A-2) 작성 필요\n",
        "        return documents_embeddings\n",
        "\n",
        "    def retrieve_doc(self, query):\n",
        "        ### Q A-3) 작성 필요\n",
        "        return doc\n",
        "\n",
        "    def cosine_similarity(self, query_embedding):\n",
        "        scores = self.documents_embeddings.matmul(query_embedding) / (\n",
        "                    torch.linalg.norm(self.documents_embeddings, dim=1) * torch.linalg.norm(query_embedding))\n",
        "        return scores\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ac84cb9-2840-4833-af07-794c5bc3c485",
      "metadata": {
        "id": "3ac84cb9-2840-4833-af07-794c5bc3c485"
      },
      "source": [
        "### Step A-2 Retriever 결과 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0864765d-3116-472f-9ec0-4fc7348ba11c",
      "metadata": {
        "collapsed": true,
        "id": "0864765d-3116-472f-9ec0-4fc7348ba11c",
        "jupyter": {
          "outputs_hidden": true
        },
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "queries = get_queries()\n",
        "spec_docs = get_specs_docs(spec_docs_dir=SPEC_DOCS_DIR)\n",
        "\n",
        "### retriever 설정 ###\n",
        "retriever = Retriever(spec_docs.copy(), embedding_model_name)\n",
        "\n",
        "for i, query in enumerate(queries):\n",
        "\n",
        "    pretty_print(str(i)+\" QUESTION\", query)\n",
        "    context = retriever.retrieve_doc(query=query)\n",
        "    pretty_print(str(i)+\" Context\",context)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16186f8f-52ff-4992-8b5d-2de5ed74aca1",
      "metadata": {
        "id": "16186f8f-52ff-4992-8b5d-2de5ed74aca1"
      },
      "source": [
        "## Step B Finetune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2345ab70-a5ce-4350-be02-96b038b3d9b4",
      "metadata": {
        "collapsed": true,
        "id": "2345ab70-a5ce-4350-be02-96b038b3d9b4",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "query = get_queries()[0] ### Galaxy에 대한 질문만 수행\n",
        "spec_docs = get_specs_docs(spec_docs_dir=SPEC_DOCS_DIR)\n",
        "\n",
        "### retriever 설정 ###\n",
        "retriever = Retriever(spec_docs.copy(), embedding_model_name)\n",
        "\n",
        "### Retriever 결과 확인 ###\n",
        "pretty_print(\"QUESTION\", query)\n",
        "context = retriever.retrieve_doc(query=query)\n",
        "pretty_print(\"RAG\",context)\n",
        "\n",
        "### sLM을 위한 prompt 정의###\n",
        "prompt = get_prompt(context=context, query=query)\n",
        "\n",
        "pretty_print(\"Prompt\",prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85f65dce-bbcb-49f2-960c-45d223c7576c",
      "metadata": {
        "id": "85f65dce-bbcb-49f2-960c-45d223c7576c"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
        "from datasets import DatasetDict\n",
        "\n",
        "path_pretrained_model = \"./models/pretrained_model/\"\n",
        "path_finetuned_model = \"./models/finetuned_model/\"\n",
        "path_json_dataset = \"./data/training_data.jsonl\"\n",
        "\n",
        "device_map = \"cpu\"\n",
        "# hyperparams for generation\n",
        "max_new_tokens = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bb5f6cd-196b-48ee-8396-cf7aea7254ce",
      "metadata": {
        "id": "8bb5f6cd-196b-48ee-8396-cf7aea7254ce"
      },
      "outputs": [],
      "source": [
        "# Tokenizing and generating a response\n",
        "def generate_response(prompt, model, tokenizer):\n",
        "    tokenized_prompt = tokenizer([prompt], return_tensors='pt')\n",
        "    generated_ids = model.generate(tokenized_prompt.input_ids,\n",
        "                   tokenizer=tokenizer,\n",
        "                   max_new_tokens=max_new_tokens)\n",
        "    #Stripping the input text from generated_ids\n",
        "    generated_ids = [\n",
        "        output_ids[len(input_ids):] for input_ids, output_ids in zip(tokenized_prompt.input_ids, generated_ids)\n",
        "    ]\n",
        "\n",
        "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "    return response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f31fd91-b691-479f-8e2f-0f44dc1cd3de",
      "metadata": {
        "id": "2f31fd91-b691-479f-8e2f-0f44dc1cd3de"
      },
      "source": [
        "### 현재 Pretrained 모델의 학습전 Response 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "316d7a0f-5431-430f-8e9a-dd5bf84d5b8c",
      "metadata": {
        "id": "316d7a0f-5431-430f-8e9a-dd5bf84d5b8c"
      },
      "outputs": [],
      "source": [
        "# Loading the pretrained model\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    path_pretrained_model,\n",
        "    device_map=device_map\n",
        ")\n",
        "\n",
        "#Loading the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    path_pretrained_model,\n",
        "    device_map=device_map\n",
        ")\n",
        "\n",
        "response = generate_response(prompt, model, tokenizer)\n",
        "print(\"response(before training):\", response)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2086768b-3657-4588-a993-43b1e804399e",
      "metadata": {
        "id": "2086768b-3657-4588-a993-43b1e804399e"
      },
      "source": [
        "Q B-1) training dataset(jsonl format) 로드하여 DatasetDict 객체를 생성하세요 (아래 조건 만족 필요)\n",
        " - split: \"train\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6794bc41-69f1-4f63-bb4b-c18a302bd7fa",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "6794bc41-69f1-4f63-bb4b-c18a302bd7fa"
      },
      "outputs": [],
      "source": [
        "# Loading the dataset\n",
        "### Q B-1-1) 작성 필요\n",
        "dataset =\n",
        "\n",
        "### Q B-1-2) 작성 필요\n",
        "dataset = dataset.map(lambda x: tokenizer(x[\"### B-1-2) 작성 필요\"], truncation=True, padding=True, max_length=512), batched=True, remove_columns=dataset[\"train\"].column_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "497855bf-bbf6-4c8e-ad4c-79eb336ffb43",
      "metadata": {
        "id": "497855bf-bbf6-4c8e-ad4c-79eb336ffb43"
      },
      "source": [
        "Q B-2) DataCollatorForLanguageModeling 객체를 생성하세요 (적절한 params 사용)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70b184a6-077c-4e61-8e03-1a34dce35e25",
      "metadata": {
        "id": "70b184a6-077c-4e61-8e03-1a34dce35e25"
      },
      "outputs": [],
      "source": [
        "# Constructing a collator\n",
        "data_collator = ### Q B-2) 작성 필요"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "645e66f5",
      "metadata": {
        "id": "645e66f5"
      },
      "source": [
        "Q B-3) 제시된 값들을 이용하여 TrainingArguments 객체를 생성하세요\n",
        "- learning rate: 7e-4\n",
        "- epoch: 100\n",
        "- batch size: 4\n",
        "- cpu 사용: True\n",
        "- report_to: \"none\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09f78c44-deea-414c-b328-2bc1f4bbd9be",
      "metadata": {
        "id": "09f78c44-deea-414c-b328-2bc1f4bbd9be"
      },
      "outputs": [],
      "source": [
        "# Setting TrainingArguments\n",
        "training_args = ### Q B-3) 작성 필요"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d546d230-b297-44c5-b2e1-0fb7f0480378",
      "metadata": {
        "id": "d546d230-b297-44c5-b2e1-0fb7f0480378"
      },
      "source": [
        "Constructing Trainer and Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cfe01aa-a12c-4e1d-8322-6d645d0403b0",
      "metadata": {
        "id": "1cfe01aa-a12c-4e1d-8322-6d645d0403b0"
      },
      "outputs": [],
      "source": [
        "# Constructing trainer, training and saving the model.\n",
        "trainer = Trainer(model, train_dataset=dataset['train'], args=training_args, data_collator=data_collator)\n",
        "trainer.train()\n",
        "\n",
        "trainer.save_model(path_finetuned_model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pretrained_model's tokenizer copy to finetuned_model\n",
        "import shutil\n",
        "copy_file_li = [\"tokenizer.json\", \"tokenizer_config.json\",\"special_tokens_map.json\"]\n",
        "for copy_file in copy_file_li:\n",
        "    shutil.copy(f\"{path_pretrained_model}/{copy_file}\", f\"{path_finetuned_model}/{copy_file}\")"
      ],
      "metadata": {
        "id": "ZD2bMPmn4pqT"
      },
      "id": "ZD2bMPmn4pqT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "79b61dcb-8f38-42d4-9f8d-bbcd498148c2",
      "metadata": {
        "id": "79b61dcb-8f38-42d4-9f8d-bbcd498148c2"
      },
      "source": [
        "#### Step B Finetune한 모델 홍보문구 결과 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fa96d68-098a-4473-8b10-aef7727f84ab",
      "metadata": {
        "id": "6fa96d68-098a-4473-8b10-aef7727f84ab"
      },
      "outputs": [],
      "source": [
        "# Loading the finetuned model\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    path_finetuned_model,\n",
        "    device_map=device_map\n",
        ")\n",
        "\n",
        "#Loading the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    path_finetuned_model,\n",
        "    device_map=device_map\n",
        ")\n",
        "\n",
        "response = generate_response(prompt, model, tokenizer)\n",
        "print(\"response(after training):\", response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b69eca16-015b-470b-85a7-9519879edb6e",
      "metadata": {
        "id": "b69eca16-015b-470b-85a7-9519879edb6e"
      },
      "source": [
        "sLM의 출력 결과를 slogan의 변수에 저장하세요"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2fa0a96-39bb-48f1-ae4d-16a435854fcd",
      "metadata": {
        "id": "e2fa0a96-39bb-48f1-ae4d-16a435854fcd"
      },
      "outputs": [],
      "source": [
        "slogan = response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c153a079-d219-4468-b2b8-6e22de95a3e6",
      "metadata": {
        "id": "c153a079-d219-4468-b2b8-6e22de95a3e6"
      },
      "source": [
        "# Step C api call로 홍보 이미지 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2f86cd8-51cb-4596-a78e-32849556c271",
      "metadata": {
        "id": "f2f86cd8-51cb-4596-a78e-32849556c271"
      },
      "outputs": [],
      "source": [
        "open_api_key = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d46929d2-5dd9-4060-b1dd-1a0f2cadfb0a",
      "metadata": {
        "id": "d46929d2-5dd9-4060-b1dd-1a0f2cadfb0a"
      },
      "source": [
        "Q C-1) 아래 지시사항을 만족하는 call_api_dalle라는 함수를 완성하세요.\n",
        "\n",
        "시험 응시자 개별 open_api_key를 하기 변수에 입력하세요\n",
        "\n",
        "[지시사항]\n",
        "* 프롬프트: target의 주변을 target과 어울리는 배경으로 채워주는 프롬프트\n",
        "* 모델이름: dall-e-3\n",
        "* 해상도: 가로, 세로 1024 px\n",
        "* 품질수준: standard\n",
        "* 생성이미지 장수: 1\n",
        "* 리턴: 생성된 이미지 위치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36663c84-7920-43b8-9e20-5be8063232d2",
      "metadata": {
        "id": "36663c84-7920-43b8-9e20-5be8063232d2"
      },
      "outputs": [],
      "source": [
        "def call_api_dalle(target =\"\"):\n",
        "    import urllib.request\n",
        "    from openai import OpenAI\n",
        "    import matplotlib.pyplot as plt\n",
        "    import matplotlib.image as img\n",
        "    client = OpenAI(api_key=open_api_key)\n",
        "    response = client.images.generate(\n",
        "        ### Q C-1) 작성 필요\n",
        "    )\n",
        "    image_url = response.data[0].url\n",
        "    image_path = f\"./{str(target)}_result.png\"\n",
        "    urllib.request.urlretrieve(image_url,image_path)\n",
        "    print(\"Image_Saved\",image_path)\n",
        "\n",
        "    plt.imshow(img.imread(image_path))\n",
        "    plt.show()\n",
        "\n",
        "    return image_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Yu1ZoSqsSxRO",
      "metadata": {
        "collapsed": true,
        "id": "Yu1ZoSqsSxRO",
        "jupyter": {
          "outputs_hidden": true
        },
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "call_api_dalle(\"갤럭시 s24 스마트폰\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45a20084-4b4d-47f5-a311-cadff95d86bf",
      "metadata": {
        "id": "45a20084-4b4d-47f5-a311-cadff95d86bf"
      },
      "source": [
        "생성된 이미지의 위치를 generated_dall_img_path 저장하세요"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e937e5a-e84a-4efc-8794-425d3ce261f9",
      "metadata": {
        "id": "1e937e5a-e84a-4efc-8794-425d3ce261f9"
      },
      "outputs": [],
      "source": [
        "generated_dall_img_path = \"./갤럭시 s24 스마트폰_result.png\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c14675a-ba9b-48e4-82c4-e89c7dbfb50c",
      "metadata": {
        "id": "1c14675a-ba9b-48e4-82c4-e89c7dbfb50c"
      },
      "source": [
        "## 홍보문구와 이미지를 최종 확인"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4aebee9e-b436-49e0-81a9-3a39216239c9",
      "metadata": {
        "id": "4aebee9e-b436-49e0-81a9-3a39216239c9"
      },
      "source": [
        "생성된 홍보문구를 출력하세요"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5128c93a-eda8-4194-969b-57b85a1514d1",
      "metadata": {
        "id": "5128c93a-eda8-4194-969b-57b85a1514d1"
      },
      "outputs": [],
      "source": [
        "pretty_print(\"홍보문구\",slogan)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "생성된 홍보이미지를 출력하세요"
      ],
      "metadata": {
        "id": "ut0NAomR5elm"
      },
      "id": "ut0NAomR5elm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57ffacf6-a8b7-45ab-b65b-b7b93148686b",
      "metadata": {
        "id": "57ffacf6-a8b7-45ab-b65b-b7b93148686b",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "display_plt_img(generated_dall_img_path) ### 제공"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f2ec367-e39e-48f1-bf9c-f856e8b15a0a",
      "metadata": {
        "id": "6f2ec367-e39e-48f1-bf9c-f856e8b15a0a"
      },
      "source": [
        "#### 실행한 jupyter notebook을 다운로드 한 후 이름을 knox id로 변경후 메일(ai.edu@samsung.com)로 제출하세요.\n",
        "#### <span style=\"color:red\">제출 파일 확인(knox id.ipynb )</span>\n",
        "#### 시험 감독관에게 이야기 후 퇴실하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e07caf7a-c677-46df-a391-d5daff993714",
      "metadata": {
        "id": "e07caf7a-c677-46df-a391-d5daff993714"
      },
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}